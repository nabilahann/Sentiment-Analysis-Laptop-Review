{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyF3PkPvSrnJ",
        "outputId": "3d387f4a-c7c5-4f5b-aee3-c5fa4f53a84a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset:\n",
        "- 0 : negative\n",
        "- 1 : neutral\n",
        "- 2 : positive"
      ],
      "metadata": {
        "id": "JeIlHBwJ203v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset laptop review"
      ],
      "metadata": {
        "id": "2012bFGgrV3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import re,string,unicodedata\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "yombzq2grwyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For data train\n",
        "df = pd.read_csv('drive/MyDrive/NLP/Laptop_review.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FlHF3HjRrYTC",
        "outputId": "73a55822-a64b-4cc6-ec57-1983db57c101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity  from   to  \n",
              "0   neutral    41   45  \n",
              "1  positive    74   86  \n",
              "2  negative    27   41  \n",
              "3  negative   109  121  \n",
              "4   neutral     4   12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb359f49-e35b-4a03-9e44-c783fb6ef459\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>neutral</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>positive</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>negative</td>\n",
              "      <td>27</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>negative</td>\n",
              "      <td>109</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb359f49-e35b-4a03-9e44-c783fb6ef459')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb359f49-e35b-4a03-9e44-c783fb6ef459 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb359f49-e35b-4a03-9e44-c783fb6ef459');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(labels=[\"from\", \"to\"], axis=1)\n",
        "df = df.loc[(df[\"polarity\"] != \"conflict\")]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PphBNTrlrZxl",
        "outputId": "b9986b8b-82e1-42c0-8884-070ec0f61b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity  \n",
              "0   neutral  \n",
              "1  positive  \n",
              "2  negative  \n",
              "3  negative  \n",
              "4   neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e89a62c0-8abd-42a7-b2b6-74556cc656f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e89a62c0-8abd-42a7-b2b6-74556cc656f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e89a62c0-8abd-42a7-b2b6-74556cc656f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e89a62c0-8abd-42a7-b2b6-74556cc656f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDSqN0iAt0LZ",
        "outputId": "1f723070-bca2-43b9-c501-0c3c51ef0b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=ToktokTokenizer()\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "SBoJV2IerwV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  return tokens\n",
        "\n",
        "df['tokens_aspect']=df['Aspect Term'].apply(tokenize_sentence)\n",
        "df['tokens']=df['Sentence'].apply(tokenize_sentence)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QCPdWYwNr1Oc",
        "outputId": "7734f959-0cda-4614-8401-2548041c1028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0   neutral                 [cord]   \n",
              "1  positive        [battery, life]   \n",
              "2  negative      [service, center]   \n",
              "3  negative  [``, sales, '', team]   \n",
              "4   neutral            [tech, guy]   \n",
              "\n",
              "                                              tokens  \n",
              "0  [I, charge, it, at, night, and, skip, taking, ...  \n",
              "1  [I, charge, it, at, night, and, skip, taking, ...  \n",
              "2  [The, tech, guy, then, said, the, service, cen...  \n",
              "3  [The, tech, guy, then, said, the, service, cen...  \n",
              "4  [The, tech, guy, then, said, the, service, cen...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a08f8bcf-cf29-45fb-be8c-3fe4fb37f3e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>positive</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>negative</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>negative</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a08f8bcf-cf29-45fb-be8c-3fe4fb37f3e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a08f8bcf-cf29-45fb-be8c-3fe4fb37f3e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a08f8bcf-cf29-45fb-be8c-3fe4fb37f3e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tags_sentence(index, arrToken, arrAspect):\n",
        "  hasil = []\n",
        "  i = 0\n",
        "  while i < len(arrToken):\n",
        "    if (arrToken[i:i+len(arrAspect)] == arrAspect):\n",
        "      for j in range(1, len(arrAspect)+1):\n",
        "        hasil.append(j)\n",
        "        i += 1\n",
        "    else:\n",
        "      hasil.append(0)\n",
        "      i += 1\n",
        "    \n",
        "    \n",
        "  return hasil\n",
        "\n",
        "hasil2 =[]\n",
        "arrToken = df[\"tokens\"].to_numpy()\n",
        "arrAspect = df[\"tokens_aspect\"].to_numpy()\n",
        "for i in range(len(df)):\n",
        "  hasil2.append(tags_sentence(i, arrToken[i], arrAspect[i]))\n",
        "\n",
        "df[\"tags\"] = hasil2\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "EtvvPrdyr4g3",
        "outputId": "b95d1563-b0c0-40fb-c8ae-7229f5130f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0   neutral                 [cord]   \n",
              "1  positive        [battery, life]   \n",
              "2  negative      [service, center]   \n",
              "3  negative  [``, sales, '', team]   \n",
              "4   neutral            [tech, guy]   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "1  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "2  [The, tech, guy, then, said, the, service, cen...   \n",
              "3  [The, tech, guy, then, said, the, service, cen...   \n",
              "4  [The, tech, guy, then, said, the, service, cen...   \n",
              "\n",
              "                                                tags  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c50f574-6246-44c2-aa84-40f4a7d091fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>positive</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>negative</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>negative</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c50f574-6246-44c2-aa84-40f4a7d091fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c50f574-6246-44c2-aa84-40f4a7d091fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c50f574-6246-44c2-aa84-40f4a7d091fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_polarity(polarity):\n",
        "  try :\n",
        "    if(polarity == \"negative\"):\n",
        "      return 0\n",
        "    elif(polarity == \"neutral\"):\n",
        "      return 1\n",
        "    elif(polarity == \"positive\"):\n",
        "      return 2\n",
        "    else : \n",
        "      raise \n",
        "\n",
        "  except :\n",
        "    return -1\n",
        "\n",
        "df[\"polarity\"] = df[\"polarity\"].apply(convert_polarity)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "rHy80Fp1uB-j",
        "outputId": "fceb5ca9-6c4a-4c2a-b8af-25c51403f46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0         1                 [cord]   \n",
              "1         2        [battery, life]   \n",
              "2         0      [service, center]   \n",
              "3         0  [``, sales, '', team]   \n",
              "4         1            [tech, guy]   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "1  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "2  [The, tech, guy, then, said, the, service, cen...   \n",
              "3  [The, tech, guy, then, said, the, service, cen...   \n",
              "4  [The, tech, guy, then, said, the, service, cen...   \n",
              "\n",
              "                                                tags  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-810f94c3-d8b4-4598-82c5-eae9da3c41d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>1</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>2</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>0</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>0</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>1</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-810f94c3-d8b4-4598-82c5-eae9da3c41d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-810f94c3-d8b4-4598-82c5-eae9da3c41d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-810f94c3-d8b4-4598-82c5-eae9da3c41d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pols_sentence(index, arr, pol):\n",
        "  hasil = []\n",
        "  for i in (arr):\n",
        "    if(i == 0):\n",
        "      hasil.append(-1)\n",
        "    else:\n",
        "      hasil.append(pol)\n",
        "  return hasil\n",
        "\n",
        "arrTag = df[\"tags\"].to_numpy()\n",
        "pols = df[\"polarity\"].to_numpy()\n",
        "hasil2 =[]\n",
        "for i in range(len(df)):\n",
        "  hasil2.append(pols_sentence(i, arrTag[i], pols[i]))\n",
        "\n",
        "df[\"pol\"] = hasil2\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "BA1zVge4sPXx",
        "outputId": "2813ae97-e302-4551-c0fb-a41b2d087a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0         1                 [cord]   \n",
              "1         2        [battery, life]   \n",
              "2         0      [service, center]   \n",
              "3         0  [``, sales, '', team]   \n",
              "4         1            [tech, guy]   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "1  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "2  [The, tech, guy, then, said, the, service, cen...   \n",
              "3  [The, tech, guy, then, said, the, service, cen...   \n",
              "4  [The, tech, guy, then, said, the, service, cen...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                 pol  \n",
              "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...  \n",
              "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "2  [-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...  \n",
              "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "4  [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66815349-b079-491b-bc31-8f95239d52a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "      <th>pol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>1</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>2</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>0</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>0</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>1</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66815349-b079-491b-bc31-8f95239d52a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66815349-b079-491b-bc31-8f95239d52a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66815349-b079-491b-bc31-8f95239d52a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arrID = df[\"id\"].to_numpy()\n",
        "arrID = list(dict.fromkeys(arrID))\n",
        "\n",
        "for id in arrID:\n",
        "  dfId = df.loc[(df[\"id\"] == id)]\n",
        "  tag = dfId.tags.to_numpy()\n",
        "  if len(dfId)> 1:\n",
        "    for i in range(len(tag)-1):\n",
        "      for j in range(len(tag[i])):\n",
        "        if tag[i][j] != tag[i+1][j]:\n",
        "          if tag[i][j] != 0:\n",
        "            tag[i+1][j] = tag[i][j]\n",
        "          else :\n",
        "            tag[i][j] = tag[i+1][j]\n",
        "\n",
        "  df.loc[(df[\"id\"] == id)][\"tags\"] = tag\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "q5xQlZT0luWW",
        "outputId": "24732376-658b-44fc-919d-6deace68ba8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0         1                 [cord]   \n",
              "1         2        [battery, life]   \n",
              "2         0      [service, center]   \n",
              "3         0  [``, sales, '', team]   \n",
              "4         1            [tech, guy]   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "1  [I, charge, it, at, night, and, skip, taking, ...   \n",
              "2  [The, tech, guy, then, said, the, service, cen...   \n",
              "3  [The, tech, guy, then, said, the, service, cen...   \n",
              "4  [The, tech, guy, then, said, the, service, cen...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                 pol  \n",
              "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...  \n",
              "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "2  [-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...  \n",
              "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "4  [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd84ae18-9a91-4ca0-9503-e3c1dc078761\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "      <th>pol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>1</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>2</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>0</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>0</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>1</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>[The, tech, guy, then, said, the, service, cen...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd84ae18-9a91-4ca0-9503-e3c1dc078761')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd84ae18-9a91-4ca0-9503-e3c1dc078761 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd84ae18-9a91-4ca0-9503-e3c1dc078761');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = []\n",
        "for s in df['tokens']:\n",
        "  temp = [str(i) for i in s]\n",
        "  sent.append(str(temp))\n",
        "\n",
        "df['tokens'] = sent\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "yuGaQTEshniB",
        "outputId": "8310dbf0-17a6-4393-a537-33a61ae2ef99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                           Sentence     Aspect Term  \\\n",
              "0  2339  I charge it at night and skip taking the cord ...            cord   \n",
              "1  2339  I charge it at night and skip taking the cord ...    battery life   \n",
              "2  1316  The tech guy then said the service center does...  service center   \n",
              "3  1316  The tech guy then said the service center does...    \"sales\" team   \n",
              "4  1316  The tech guy then said the service center does...        tech guy   \n",
              "\n",
              "   polarity          tokens_aspect  \\\n",
              "0         1                 [cord]   \n",
              "1         2        [battery, life]   \n",
              "2         0      [service, center]   \n",
              "3         0  [``, sales, '', team]   \n",
              "4         1            [tech, guy]   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  ['I', 'charge', 'it', 'at', 'night', 'and', 's...   \n",
              "1  ['I', 'charge', 'it', 'at', 'night', 'and', 's...   \n",
              "2  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "3  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "4  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                 pol  \n",
              "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...  \n",
              "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "2  [-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...  \n",
              "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "4  [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2489955a-d9f3-4e0d-8057-d2df7c46c3f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Aspect Term</th>\n",
              "      <th>polarity</th>\n",
              "      <th>tokens_aspect</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "      <th>pol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>cord</td>\n",
              "      <td>1</td>\n",
              "      <td>[cord]</td>\n",
              "      <td>['I', 'charge', 'it', 'at', 'night', 'and', 's...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2339</td>\n",
              "      <td>I charge it at night and skip taking the cord ...</td>\n",
              "      <td>battery life</td>\n",
              "      <td>2</td>\n",
              "      <td>[battery, life]</td>\n",
              "      <td>['I', 'charge', 'it', 'at', 'night', 'and', 's...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>service center</td>\n",
              "      <td>0</td>\n",
              "      <td>[service, center]</td>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>\"sales\" team</td>\n",
              "      <td>0</td>\n",
              "      <td>[``, sales, '', team]</td>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1316</td>\n",
              "      <td>The tech guy then said the service center does...</td>\n",
              "      <td>tech guy</td>\n",
              "      <td>1</td>\n",
              "      <td>[tech, guy]</td>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2489955a-d9f3-4e0d-8057-d2df7c46c3f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2489955a-d9f3-4e0d-8057-d2df7c46c3f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2489955a-d9f3-4e0d-8057-d2df7c46c3f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df[\"tokens\"] = [str(x) for x in df[\"tokens\"]]\n",
        "df[\"tokens\"][0]"
      ],
      "metadata": {
        "id": "ENtoJkuisfbM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "edde6aa5-ec36-44d1-e026-0ea27884bd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"tags\"] = [str(x) for x in df[\"tags\"]]\n",
        "df[\"tags\"][0]"
      ],
      "metadata": {
        "id": "w_9ceRugsilH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0d3859eb-61fd-4529-aeca-458475b0dd26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"pol\"] = [str(x) for x in df[\"pol\"]]\n",
        "df[\"pol\"][0]"
      ],
      "metadata": {
        "id": "gFjsu69UslGm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "beec9889-f40c-4cb9-d7aa-af594e9bfdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(labels=[\"id\", \"Sentence\", \"Aspect Term\", \"polarity\", \"tokens_aspect\"], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0ohnFq61sroA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "32666b5d-f40b-457d-b9b5-32dc2cee6001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  \\\n",
              "0  ['I', 'charge', 'it', 'at', 'night', 'and', 's...   \n",
              "1  ['I', 'charge', 'it', 'at', 'night', 'and', 's...   \n",
              "2  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "3  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "4  ['The', 'tech', 'guy', 'then', 'said', 'the', ...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                 pol  \n",
              "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...  \n",
              "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "2  [-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...  \n",
              "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
              "4  [-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17fe74fd-eea2-4c4d-a0ad-0cb00e1b57b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "      <th>pol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['I', 'charge', 'it', 'at', 'night', 'and', 's...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['I', 'charge', 'it', 'at', 'night', 'and', 's...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['The', 'tech', 'guy', 'then', 'said', 'the', ...</td>\n",
              "      <td>[0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[-1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17fe74fd-eea2-4c4d-a0ad-0cb00e1b57b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17fe74fd-eea2-4c4d-a0ad-0cb00e1b57b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17fe74fd-eea2-4c4d-a0ad-0cb00e1b57b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df.loc[: 2000]\n",
        "df_test= df.loc[2000:]\n",
        "\n",
        "df.to_csv('laptop.csv')\n",
        "df_train.to_csv('drive/MyDrive/NLP/laptop_train.csv')\n",
        "df_test.to_csv('drive/MyDrive/NLP/laptop_test.csv')"
      ],
      "metadata": {
        "id": "gdqAmdCkuXm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# With Bert"
      ],
      "metadata": {
        "id": "rCFTl_UCraTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "4HyE0tLsEeOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset_ABSA(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens, tags, pols = self.df.iloc[idx, :3].values\n",
        "        tokens = tokens.replace(\"'\", \"\").strip(\"][\").split(', ')\n",
        "        tags = tags.strip('][').split(', ')\n",
        "        pols = pols.strip('][').split(', ')\n",
        "\n",
        "        bert_tokens = []\n",
        "        bert_att = []\n",
        "        pols_label = 0\n",
        "        for i in range(len(tokens)):\n",
        "            t = self.tokenizer.tokenize(tokens[i])\n",
        "            bert_tokens += t\n",
        "            if int(pols[i]) != -1:\n",
        "                bert_att += t\n",
        "                pols_label = int(pols[i])\n",
        "\n",
        "        segment_tensor = [0] + [0]*len(bert_tokens) + [0] + [1]*len(bert_att)\n",
        "        bert_tokens = ['[cls]'] + bert_tokens + ['[sep]'] + bert_att\n",
        "        \n",
        "\n",
        "        bert_ids = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
        "\n",
        "        ids_tensor = torch.tensor(bert_ids)\n",
        "        pols_tensor = torch.tensor(pols_label)\n",
        "        segment_tensor = torch.tensor(segment_tensor)\n",
        "\n",
        "        return bert_tokens, ids_tensor, segment_tensor, pols_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "L0YCU4JBsxN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Bert"
      ],
      "metadata": {
        "id": "r4TPyU8_tASj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah1PfMLftSiy",
        "outputId": "eed34d88-86e0-477f-e1a5-f6147c2ff628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 35.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "import torch\n",
        "\n",
        "class bert_ABSA(torch.nn.Module):\n",
        "    def __init__(self, pretrain_model):\n",
        "        super(bert_ABSA, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(pretrain_model)\n",
        "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, 3)\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, ids_tensors, lable_tensors, masks_tensors, segments_tensors):\n",
        "        _, pooled_outputs = self.bert(input_ids=ids_tensors, attention_mask=masks_tensors, token_type_ids=segments_tensors, return_dict=False)\n",
        "        linear_outputs = self.linear(pooled_outputs)\n",
        "\n",
        "        if lable_tensors is not None:\n",
        "            loss = self.loss_fn(linear_outputs, lable_tensors)\n",
        "            return loss\n",
        "        else:\n",
        "            return linear_outputs"
      ],
      "metadata": {
        "id": "TuvuXEAds5Lr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class bert_ATE(torch.nn.Module):\n",
        "    def __init__(self, pretrain_model):\n",
        "        super(bert_ATE, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(pretrain_model)\n",
        "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, 3)\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, ids_tensors, tags_tensors, masks_tensors):\n",
        "        bert_outputs,_ = self.bert(input_ids=ids_tensors, attention_mask=masks_tensors, return_dict=False)\n",
        "        # print(bert_outputs.size())\n",
        "        linear_outputs = self.linear(bert_outputs)\n",
        "        # print(linear_outputs.size())\n",
        "\n",
        "        if tags_tensors is not None:\n",
        "            tags_tensors = tags_tensors.view(-1)\n",
        "            linear_outputs = linear_outputs.view(-1,3)\n",
        "            # print(linear_outputs.size())\n",
        "            # print(tags_tensors.size())\n",
        "            loss = self.loss_fn(linear_outputs, tags_tensors)\n",
        "            return loss\n",
        "        else:\n",
        "            return linear_outputs"
      ],
      "metadata": {
        "id": "sVbxGLtwNcXZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "On9RNK9atane"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrain_model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrain_model_name)\n",
        "lr = 2e-5\n",
        "model_ATE = bert_ATE(pretrain_model_name).to(DEVICE)\n",
        "optimizer_ATE = torch.optim.Adam(model_ATE.parameters(), lr=lr)\n",
        "model_ABSA = bert_ABSA(pretrain_model_name).to(DEVICE)\n",
        "optimizer_ABSA = torch.optim.Adam(model_ABSA.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7Vu51FqtqAd",
        "outputId": "affb7f75-9369-448f-d94a-8ea63113d2a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evl_time(t):\n",
        "    min, sec= divmod(t, 60)\n",
        "    hr, min = divmod(min, 60)\n",
        "    return int(hr), int(min), int(sec)\n",
        "\n",
        "def load_model(model, path):\n",
        "    model.load_state_dict(torch.load(path), strict=False)\n",
        "    return model\n",
        "    \n",
        "def save_model(model, name):\n",
        "    torch.save(model.state_dict(), name)"
      ],
      "metadata": {
        "id": "xMQOYbPptwfJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ds = dataset_ABSA(df_train, tokenizer)\n",
        "X_test_ds = dataset_ABSA(df_test, tokenizer)"
      ],
      "metadata": {
        "id": "2kQJCrq6tzYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w,x,y,z = X_train_ds.__getitem__(0)\n",
        "print(w)\n",
        "print(len(w))\n",
        "print(x)\n",
        "print(len(x))\n",
        "print(y)\n",
        "print(len(y))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7E9u4p9uR_l",
        "outputId": "8db3d2e4-a478-4374-ad0f-6030a4cc2acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[cls]', 'i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.', '[sep]', 'cord']\n",
            "22\n",
            "tensor([  100,  1045,  3715,  2009,  2012,  2305,  1998, 13558,  2635,  1996,\n",
            "        11601,  2007,  2033,  2138,  1997,  1996,  2204,  6046,  2166,  1012,\n",
            "          100, 11601])\n",
            "22\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "22\n",
            "tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mini_batch2(samples):\n",
        "    ids_tensors = [s[1] for s in samples]\n",
        "    ids_tensors = pad_sequence(ids_tensors, batch_first=True)\n",
        "\n",
        "    segments_tensors = [s[2] for s in samples]\n",
        "    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
        "\n",
        "    label_ids = torch.stack([s[3] for s in samples])\n",
        "    \n",
        "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
        "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
        "\n",
        "    return ids_tensors, segments_tensors, masks_tensors, label_ids"
      ],
      "metadata": {
        "id": "jzmuGjEGuakp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(X_train_ds, batch_size=20, collate_fn=create_mini_batch2, shuffle = True)\n",
        "test_loader = DataLoader(X_test_ds, batch_size=30, collate_fn=create_mini_batch2, shuffle = True)"
      ],
      "metadata": {
        "id": "mBZDJIFRudMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQvdxGdPPL9I",
        "outputId": "3237c3fd-94f0-44f9-e413-8026eba28e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fa469644950>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_ABSA(loader, epochs):\n",
        "    all_data = len(loader)\n",
        "    for epoch in range(epochs):\n",
        "        finish_data = 0\n",
        "        losses = []\n",
        "        current_times = []\n",
        "        correct_predictions = 0\n",
        "        \n",
        "        for data in loader:\n",
        "            t0 = time.time()\n",
        "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
        "            ids_tensors = ids_tensors.to(DEVICE)\n",
        "            segments_tensors = segments_tensors.to(DEVICE)\n",
        "            label_ids = label_ids.to(DEVICE)\n",
        "            masks_tensors = masks_tensors.to(DEVICE)\n",
        "\n",
        "            loss = model_ABSA(ids_tensors=ids_tensors, lable_tensors=label_ids, masks_tensors=masks_tensors, segments_tensors=segments_tensors )\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer_ABSA.step()\n",
        "            optimizer_ABSA.zero_grad()\n",
        "\n",
        "            finish_data += 1\n",
        "            current_times.append(round(time.time()-t0,3))\n",
        "            current = np.mean(current_times)\n",
        "            hr, min, sec = evl_time(current*(all_data-finish_data) + current*all_data*(epochs-epoch-1))\n",
        "            print('epoch:', epoch, \" batch:\", finish_data, \"/\" , all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min,\" sec:\", sec)         \n",
        "\n",
        "        save_model(model_ABSA, 'bert_ABSA2.pkl')\n",
        "        save_model(model_ABSA, 'drive/MyDrive/NLP/bert_ABSA2.pkl')\n",
        "        \n",
        "def test_model_ABSA(loader):\n",
        "    pred = []\n",
        "    trueth = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "\n",
        "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
        "            ids_tensors = ids_tensors.to(DEVICE)\n",
        "            segments_tensors = segments_tensors.to(DEVICE)\n",
        "            masks_tensors = masks_tensors.to(DEVICE)\n",
        "\n",
        "            outputs = model_ABSA(ids_tensors, None, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
        "            \n",
        "            _, predictions = torch.max(outputs, dim=1)\n",
        "\n",
        "            pred += list([int(i) for i in predictions])\n",
        "            trueth += list([int(i) for i in label_ids])\n",
        "\n",
        "    return trueth, pred"
      ],
      "metadata": {
        "id": "JkPvHnvBukkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_model_ABSA(sentence, aspect, tokenizer):\n",
        "    t1 = tokenizer.tokenize(sentence)\n",
        "    t2 = tokenizer.tokenize(aspect)\n",
        "\n",
        "    word_pieces = ['[cls]']\n",
        "    word_pieces += t1\n",
        "    word_pieces += ['[sep]']\n",
        "    word_pieces += t2\n",
        "\n",
        "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
        "\n",
        "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
        "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
        "        _, predictions = torch.max(outputs, dim=1)\n",
        "    \n",
        "    return word_pieces, predictions, outputs"
      ],
      "metadata": {
        "id": "6GQ9FQUusw7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time train_model_ABSA(train_loader, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4xSE3B1unhl",
        "outputId": "7e055244-9aaf-4180-cf11-b0f18ff26289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  batch: 1 / 98  loss: 1.1043999195098877  hr: 4  min: 12  sec: 45\n",
            "epoch: 0  batch: 2 / 98  loss: 1.0888811349868774  hr: 2  min: 52  sec: 35\n",
            "epoch: 0  batch: 3 / 98  loss: 1.1080188751220703  hr: 2  min: 41  sec: 38\n",
            "epoch: 0  batch: 4 / 98  loss: 1.0869856476783752  hr: 2  min: 32  sec: 42\n",
            "epoch: 0  batch: 5 / 98  loss: 1.0846914052963257  hr: 2  min: 29  sec: 29\n",
            "epoch: 0  batch: 6 / 98  loss: 1.0872076551119487  hr: 2  min: 32  sec: 7\n",
            "epoch: 0  batch: 7 / 98  loss: 1.0659072228840418  hr: 2  min: 28  sec: 31\n",
            "epoch: 0  batch: 8 / 98  loss: 1.0670467764139175  hr: 2  min: 32  sec: 28\n",
            "epoch: 0  batch: 9 / 98  loss: 1.0648455487357245  hr: 2  min: 31  sec: 41\n",
            "epoch: 0  batch: 10 / 98  loss: 1.0596205115318298  hr: 2  min: 31  sec: 4\n",
            "epoch: 0  batch: 11 / 98  loss: 1.0551201646978206  hr: 2  min: 28  sec: 34\n",
            "epoch: 0  batch: 12 / 98  loss: 1.0503843873739243  hr: 2  min: 30  sec: 16\n",
            "epoch: 0  batch: 13 / 98  loss: 1.0509944833241975  hr: 2  min: 29  sec: 54\n",
            "epoch: 0  batch: 14 / 98  loss: 1.055994642632348  hr: 2  min: 28  sec: 40\n",
            "epoch: 0  batch: 15 / 98  loss: 1.063207463423411  hr: 2  min: 26  sec: 0\n",
            "epoch: 0  batch: 16 / 98  loss: 1.070027556270361  hr: 2  min: 24  sec: 56\n",
            "epoch: 0  batch: 17 / 98  loss: 1.0664699182790869  hr: 2  min: 22  sec: 10\n",
            "epoch: 0  batch: 18 / 98  loss: 1.0627176894081964  hr: 2  min: 20  sec: 17\n",
            "epoch: 0  batch: 19 / 98  loss: 1.055794596672058  hr: 2  min: 17  sec: 31\n",
            "epoch: 0  batch: 20 / 98  loss: 1.046286979317665  hr: 2  min: 17  sec: 36\n",
            "epoch: 0  batch: 21 / 98  loss: 1.0438367213521684  hr: 2  min: 15  sec: 57\n",
            "epoch: 0  batch: 22 / 98  loss: 1.0437119684436105  hr: 2  min: 17  sec: 1\n",
            "epoch: 0  batch: 23 / 98  loss: 1.0387483031853386  hr: 2  min: 16  sec: 8\n",
            "epoch: 0  batch: 24 / 98  loss: 1.0361085707942645  hr: 2  min: 16  sec: 29\n",
            "epoch: 0  batch: 25 / 98  loss: 1.0417914843559266  hr: 2  min: 16  sec: 23\n",
            "epoch: 0  batch: 26 / 98  loss: 1.0428762642236857  hr: 2  min: 14  sec: 48\n",
            "epoch: 0  batch: 27 / 98  loss: 1.038500721807833  hr: 2  min: 14  sec: 21\n",
            "epoch: 0  batch: 28 / 98  loss: 1.0414536190884454  hr: 2  min: 12  sec: 51\n",
            "epoch: 0  batch: 29 / 98  loss: 1.037312900197917  hr: 2  min: 13  sec: 32\n",
            "epoch: 0  batch: 30 / 98  loss: 1.0316927830378215  hr: 2  min: 11  sec: 58\n",
            "epoch: 0  batch: 31 / 98  loss: 1.0331343104762416  hr: 2  min: 11  sec: 22\n",
            "epoch: 0  batch: 32 / 98  loss: 1.0310519710183144  hr: 2  min: 10  sec: 27\n",
            "epoch: 0  batch: 33 / 98  loss: 1.031920060966954  hr: 2  min: 10  sec: 34\n",
            "epoch: 0  batch: 34 / 98  loss: 1.0290939194314621  hr: 2  min: 9  sec: 50\n",
            "epoch: 0  batch: 35 / 98  loss: 1.0286707077707564  hr: 2  min: 9  sec: 16\n",
            "epoch: 0  batch: 36 / 98  loss: 1.0272442483239703  hr: 2  min: 8  sec: 7\n",
            "epoch: 0  batch: 37 / 98  loss: 1.0243811800673202  hr: 2  min: 7  sec: 26\n",
            "epoch: 0  batch: 38 / 98  loss: 1.0216276426064341  hr: 2  min: 6  sec: 42\n",
            "epoch: 0  batch: 39 / 98  loss: 1.0163692725010407  hr: 2  min: 6  sec: 54\n",
            "epoch: 0  batch: 40 / 98  loss: 1.01190427839756  hr: 2  min: 7  sec: 5\n",
            "epoch: 0  batch: 41 / 98  loss: 1.0089647115730658  hr: 2  min: 7  sec: 6\n",
            "epoch: 0  batch: 42 / 98  loss: 1.0053248008092244  hr: 2  min: 6  sec: 52\n",
            "epoch: 0  batch: 43 / 98  loss: 1.001018644765366  hr: 2  min: 7  sec: 2\n",
            "epoch: 0  batch: 44 / 98  loss: 0.9969918754967776  hr: 2  min: 6  sec: 33\n",
            "epoch: 0  batch: 45 / 98  loss: 0.9980824126137627  hr: 2  min: 5  sec: 46\n",
            "epoch: 0  batch: 46 / 98  loss: 0.9943974588228308  hr: 2  min: 6  sec: 23\n",
            "epoch: 0  batch: 47 / 98  loss: 0.9882362662477696  hr: 2  min: 5  sec: 31\n",
            "epoch: 0  batch: 48 / 98  loss: 0.9821892666320006  hr: 2  min: 5  sec: 1\n",
            "epoch: 0  batch: 49 / 98  loss: 0.9766828198822177  hr: 2  min: 4  sec: 37\n",
            "epoch: 0  batch: 50 / 98  loss: 0.9790257632732391  hr: 2  min: 4  sec: 36\n",
            "epoch: 0  batch: 51 / 98  loss: 0.977465594516081  hr: 2  min: 4  sec: 12\n",
            "epoch: 0  batch: 52 / 98  loss: 0.9798197173155271  hr: 2  min: 3  sec: 49\n",
            "epoch: 0  batch: 53 / 98  loss: 0.9788750027710537  hr: 2  min: 3  sec: 15\n",
            "epoch: 0  batch: 54 / 98  loss: 0.9776089621914757  hr: 2  min: 2  sec: 51\n",
            "epoch: 0  batch: 55 / 98  loss: 0.9737038178877397  hr: 2  min: 2  sec: 34\n",
            "epoch: 0  batch: 56 / 98  loss: 0.9692490760769162  hr: 2  min: 2  sec: 45\n",
            "epoch: 0  batch: 57 / 98  loss: 0.9666798522597865  hr: 2  min: 2  sec: 13\n",
            "epoch: 0  batch: 58 / 98  loss: 0.9642196472348838  hr: 2  min: 2  sec: 12\n",
            "epoch: 0  batch: 59 / 98  loss: 0.9678996326559681  hr: 2  min: 1  sec: 37\n",
            "epoch: 0  batch: 60 / 98  loss: 0.9641357521216075  hr: 2  min: 1  sec: 31\n",
            "epoch: 0  batch: 61 / 98  loss: 0.9618806047517745  hr: 2  min: 0  sec: 51\n",
            "epoch: 0  batch: 62 / 98  loss: 0.9572175481627064  hr: 2  min: 1  sec: 36\n",
            "epoch: 0  batch: 63 / 98  loss: 0.9548485420999073  hr: 2  min: 1  sec: 24\n",
            "epoch: 0  batch: 64 / 98  loss: 0.9527886444702744  hr: 2  min: 1  sec: 24\n",
            "epoch: 0  batch: 65 / 98  loss: 0.9474834808936485  hr: 2  min: 1  sec: 1\n",
            "epoch: 0  batch: 66 / 98  loss: 0.9459610292405793  hr: 2  min: 1  sec: 24\n",
            "epoch: 0  batch: 67 / 98  loss: 0.9393893782772235  hr: 2  min: 0  sec: 55\n",
            "epoch: 0  batch: 68 / 98  loss: 0.9374237007954541  hr: 2  min: 0  sec: 22\n",
            "epoch: 0  batch: 69 / 98  loss: 0.9371263738991558  hr: 2  min: 0  sec: 17\n",
            "epoch: 0  batch: 70 / 98  loss: 0.9365950158664158  hr: 2  min: 0  sec: 42\n",
            "epoch: 0  batch: 71 / 98  loss: 0.9336087317533897  hr: 2  min: 0  sec: 57\n",
            "epoch: 0  batch: 72 / 98  loss: 0.9310621180468135  hr: 2  min: 0  sec: 43\n",
            "epoch: 0  batch: 73 / 98  loss: 0.9265837873498054  hr: 2  min: 0  sec: 41\n",
            "epoch: 0  batch: 74 / 98  loss: 0.9237663254544541  hr: 2  min: 0  sec: 27\n",
            "epoch: 0  batch: 75 / 98  loss: 0.9232194860776265  hr: 1  min: 59  sec: 58\n",
            "epoch: 0  batch: 76 / 98  loss: 0.9210003755594555  hr: 1  min: 59  sec: 38\n",
            "epoch: 0  batch: 77 / 98  loss: 0.913836985052406  hr: 1  min: 59  sec: 56\n",
            "epoch: 0  batch: 78 / 98  loss: 0.9110930313666662  hr: 1  min: 59  sec: 26\n",
            "epoch: 0  batch: 79 / 98  loss: 0.9095025270045558  hr: 1  min: 59  sec: 7\n",
            "epoch: 0  batch: 80 / 98  loss: 0.9096621323376894  hr: 1  min: 58  sec: 47\n",
            "epoch: 0  batch: 81 / 98  loss: 0.9052105100802433  hr: 1  min: 58  sec: 37\n",
            "epoch: 0  batch: 82 / 98  loss: 0.9018507363592706  hr: 1  min: 58  sec: 18\n",
            "epoch: 0  batch: 83 / 98  loss: 0.8973305487489126  hr: 1  min: 58  sec: 36\n",
            "epoch: 0  batch: 84 / 98  loss: 0.8998177466647965  hr: 1  min: 58  sec: 30\n",
            "epoch: 0  batch: 85 / 98  loss: 0.8976491707212785  hr: 1  min: 58  sec: 20\n",
            "epoch: 0  batch: 86 / 98  loss: 0.8957701633835948  hr: 1  min: 58  sec: 10\n",
            "epoch: 0  batch: 87 / 98  loss: 0.8914227269846817  hr: 1  min: 58  sec: 55\n",
            "epoch: 0  batch: 88 / 98  loss: 0.8887057863175869  hr: 1  min: 58  sec: 52\n",
            "epoch: 0  batch: 89 / 98  loss: 0.8868191868401645  hr: 1  min: 58  sec: 31\n",
            "epoch: 0  batch: 90 / 98  loss: 0.8862467232677672  hr: 1  min: 57  sec: 59\n",
            "epoch: 0  batch: 91 / 98  loss: 0.8879911267495417  hr: 1  min: 58  sec: 4\n",
            "epoch: 0  batch: 92 / 98  loss: 0.8845051400687384  hr: 1  min: 58  sec: 27\n",
            "epoch: 0  batch: 93 / 98  loss: 0.8800766701980304  hr: 1  min: 58  sec: 30\n",
            "epoch: 0  batch: 94 / 98  loss: 0.8774794178440216  hr: 1  min: 58  sec: 16\n",
            "epoch: 0  batch: 95 / 98  loss: 0.8750408113002777  hr: 1  min: 58  sec: 21\n",
            "epoch: 0  batch: 96 / 98  loss: 0.8753273012116551  hr: 1  min: 58  sec: 2\n",
            "epoch: 0  batch: 97 / 98  loss: 0.8729940305665597  hr: 1  min: 58  sec: 5\n",
            "epoch: 0  batch: 98 / 98  loss: 0.8717116388131161  hr: 1  min: 57  sec: 55\n",
            "epoch: 1  batch: 1 / 98  loss: 0.5814963579177856  hr: 2  min: 47  sec: 17\n",
            "epoch: 1  batch: 2 / 98  loss: 0.4982024282217026  hr: 2  min: 10  sec: 20\n",
            "epoch: 1  batch: 3 / 98  loss: 0.5643182496229807  hr: 2  min: 20  sec: 5\n",
            "epoch: 1  batch: 4 / 98  loss: 0.5628845319151878  hr: 2  min: 14  sec: 56\n",
            "epoch: 1  batch: 5 / 98  loss: 0.5951503932476043  hr: 2  min: 13  sec: 5\n",
            "epoch: 1  batch: 6 / 98  loss: 0.561957652370135  hr: 2  min: 16  sec: 22\n",
            "epoch: 1  batch: 7 / 98  loss: 0.5576886066368648  hr: 2  min: 13  sec: 23\n",
            "epoch: 1  batch: 8 / 98  loss: 0.5760115496814251  hr: 2  min: 10  sec: 8\n",
            "epoch: 1  batch: 9 / 98  loss: 0.5568610827128092  hr: 2  min: 6  sec: 45\n",
            "epoch: 1  batch: 10 / 98  loss: 0.5619534850120544  hr: 2  min: 8  sec: 41\n",
            "epoch: 1  batch: 11 / 98  loss: 0.571294822476127  hr: 2  min: 6  sec: 38\n",
            "epoch: 1  batch: 12 / 98  loss: 0.5868039627869924  hr: 2  min: 5  sec: 20\n",
            "epoch: 1  batch: 13 / 98  loss: 0.5904165460513189  hr: 2  min: 2  sec: 53\n",
            "epoch: 1  batch: 14 / 98  loss: 0.5783665605953762  hr: 2  min: 3  sec: 35\n",
            "epoch: 1  batch: 15 / 98  loss: 0.5649718979994456  hr: 2  min: 2  sec: 55\n",
            "epoch: 1  batch: 16 / 98  loss: 0.5708269011229277  hr: 2  min: 1  sec: 58\n",
            "epoch: 1  batch: 17 / 98  loss: 0.5608058326384601  hr: 2  min: 1  sec: 55\n",
            "epoch: 1  batch: 18 / 98  loss: 0.5533575597736571  hr: 2  min: 2  sec: 10\n",
            "epoch: 1  batch: 19 / 98  loss: 0.5584700625193747  hr: 2  min: 2  sec: 10\n",
            "epoch: 1  batch: 20 / 98  loss: 0.5481965631246567  hr: 2  min: 0  sec: 55\n",
            "epoch: 1  batch: 21 / 98  loss: 0.5522499425070626  hr: 2  min: 0  sec: 50\n",
            "epoch: 1  batch: 22 / 98  loss: 0.5731844414364208  hr: 2  min: 0  sec: 6\n",
            "epoch: 1  batch: 23 / 98  loss: 0.5636507246805273  hr: 1  min: 58  sec: 28\n",
            "epoch: 1  batch: 24 / 98  loss: 0.5643764932950338  hr: 1  min: 57  sec: 4\n",
            "epoch: 1  batch: 25 / 98  loss: 0.5621928644180297  hr: 1  min: 58  sec: 5\n",
            "epoch: 1  batch: 26 / 98  loss: 0.5498789852628341  hr: 1  min: 56  sec: 38\n",
            "epoch: 1  batch: 27 / 98  loss: 0.5533834127364335  hr: 1  min: 56  sec: 0\n",
            "epoch: 1  batch: 28 / 98  loss: 0.5526979421930653  hr: 1  min: 54  sec: 50\n",
            "epoch: 1  batch: 29 / 98  loss: 0.5514149485990919  hr: 1  min: 54  sec: 30\n",
            "epoch: 1  batch: 30 / 98  loss: 0.5554110532005628  hr: 1  min: 54  sec: 17\n",
            "epoch: 1  batch: 31 / 98  loss: 0.5521212224998782  hr: 1  min: 54  sec: 18\n",
            "epoch: 1  batch: 32 / 98  loss: 0.5448172246105969  hr: 1  min: 53  sec: 41\n",
            "epoch: 1  batch: 33 / 98  loss: 0.5449797009879892  hr: 1  min: 53  sec: 41\n",
            "epoch: 1  batch: 34 / 98  loss: 0.5431337185642299  hr: 1  min: 53  sec: 1\n",
            "epoch: 1  batch: 35 / 98  loss: 0.5379217228719166  hr: 1  min: 52  sec: 33\n",
            "epoch: 1  batch: 36 / 98  loss: 0.537935928752025  hr: 1  min: 52  sec: 20\n",
            "epoch: 1  batch: 37 / 98  loss: 0.5308534756705567  hr: 1  min: 52  sec: 15\n",
            "epoch: 1  batch: 38 / 98  loss: 0.5335160207591558  hr: 1  min: 51  sec: 58\n",
            "epoch: 1  batch: 39 / 98  loss: 0.531813329228988  hr: 1  min: 51  sec: 40\n",
            "epoch: 1  batch: 40 / 98  loss: 0.5271516766399145  hr: 1  min: 51  sec: 22\n",
            "epoch: 1  batch: 41 / 98  loss: 0.523359114440476  hr: 1  min: 51  sec: 22\n",
            "epoch: 1  batch: 42 / 98  loss: 0.519214102554889  hr: 1  min: 50  sec: 45\n",
            "epoch: 1  batch: 43 / 98  loss: 0.5154979807692904  hr: 1  min: 51  sec: 11\n",
            "epoch: 1  batch: 44 / 98  loss: 0.5119455642998219  hr: 1  min: 52  sec: 0\n",
            "epoch: 1  batch: 45 / 98  loss: 0.5133890320857366  hr: 1  min: 51  sec: 21\n",
            "epoch: 1  batch: 46 / 98  loss: 0.5118411724334178  hr: 1  min: 51  sec: 23\n",
            "epoch: 1  batch: 47 / 98  loss: 0.5153825330607434  hr: 1  min: 51  sec: 25\n",
            "epoch: 1  batch: 48 / 98  loss: 0.5165438810363412  hr: 1  min: 51  sec: 38\n",
            "epoch: 1  batch: 49 / 98  loss: 0.5181203274702539  hr: 1  min: 51  sec: 12\n",
            "epoch: 1  batch: 50 / 98  loss: 0.5169779619574547  hr: 1  min: 51  sec: 45\n",
            "epoch: 1  batch: 51 / 98  loss: 0.5200396013610503  hr: 1  min: 51  sec: 36\n",
            "epoch: 1  batch: 52 / 98  loss: 0.5252349637448788  hr: 1  min: 50  sec: 47\n",
            "epoch: 1  batch: 53 / 98  loss: 0.5296515954552956  hr: 1  min: 50  sec: 22\n",
            "epoch: 1  batch: 54 / 98  loss: 0.5294672435632458  hr: 1  min: 50  sec: 13\n",
            "epoch: 1  batch: 55 / 98  loss: 0.5298471610654484  hr: 1  min: 50  sec: 8\n",
            "epoch: 1  batch: 56 / 98  loss: 0.5314856988510915  hr: 1  min: 50  sec: 8\n",
            "epoch: 1  batch: 57 / 98  loss: 0.5284254302581152  hr: 1  min: 49  sec: 34\n",
            "epoch: 1  batch: 58 / 98  loss: 0.5277146530048601  hr: 1  min: 49  sec: 15\n",
            "epoch: 1  batch: 59 / 98  loss: 0.5249837225271483  hr: 1  min: 48  sec: 52\n",
            "epoch: 1  batch: 60 / 98  loss: 0.5229369444151719  hr: 1  min: 48  sec: 44\n",
            "epoch: 1  batch: 61 / 98  loss: 0.5258911029725778  hr: 1  min: 48  sec: 38\n",
            "epoch: 1  batch: 62 / 98  loss: 0.5254471184265229  hr: 1  min: 48  sec: 19\n",
            "epoch: 1  batch: 63 / 98  loss: 0.5284986209774775  hr: 1  min: 47  sec: 59\n",
            "epoch: 1  batch: 64 / 98  loss: 0.5272315770853311  hr: 1  min: 47  sec: 12\n",
            "epoch: 1  batch: 65 / 98  loss: 0.529785873568975  hr: 1  min: 47  sec: 17\n",
            "epoch: 1  batch: 66 / 98  loss: 0.5327500703208374  hr: 1  min: 47  sec: 14\n",
            "epoch: 1  batch: 67 / 98  loss: 0.5354826835109227  hr: 1  min: 46  sec: 44\n",
            "epoch: 1  batch: 68 / 98  loss: 0.5396072156727314  hr: 1  min: 46  sec: 19\n",
            "epoch: 1  batch: 69 / 98  loss: 0.537983138276183  hr: 1  min: 45  sec: 54\n",
            "epoch: 1  batch: 70 / 98  loss: 0.5380756580403873  hr: 1  min: 45  sec: 40\n",
            "epoch: 1  batch: 71 / 98  loss: 0.5389407157478198  hr: 1  min: 45  sec: 22\n",
            "epoch: 1  batch: 72 / 98  loss: 0.5352141859216822  hr: 1  min: 45  sec: 15\n",
            "epoch: 1  batch: 73 / 98  loss: 0.5391722707307502  hr: 1  min: 44  sec: 37\n",
            "epoch: 1  batch: 74 / 98  loss: 0.5356120835687663  hr: 1  min: 44  sec: 37\n",
            "epoch: 1  batch: 75 / 98  loss: 0.5365919150908788  hr: 1  min: 44  sec: 11\n",
            "epoch: 1  batch: 76 / 98  loss: 0.5335239522943371  hr: 1  min: 44  sec: 1\n",
            "epoch: 1  batch: 77 / 98  loss: 0.5326117867386186  hr: 1  min: 43  sec: 38\n",
            "epoch: 1  batch: 78 / 98  loss: 0.5336275393000016  hr: 1  min: 43  sec: 47\n",
            "epoch: 1  batch: 79 / 98  loss: 0.5316940585646448  hr: 1  min: 43  sec: 24\n",
            "epoch: 1  batch: 80 / 98  loss: 0.5337096819654107  hr: 1  min: 43  sec: 4\n",
            "epoch: 1  batch: 81 / 98  loss: 0.534650699775896  hr: 1  min: 42  sec: 34\n",
            "epoch: 1  batch: 82 / 98  loss: 0.534297999994057  hr: 1  min: 42  sec: 30\n",
            "epoch: 1  batch: 83 / 98  loss: 0.5307689364775118  hr: 1  min: 41  sec: 59\n",
            "epoch: 1  batch: 84 / 98  loss: 0.5309349644396987  hr: 1  min: 42  sec: 8\n",
            "epoch: 1  batch: 85 / 98  loss: 0.5315541083321852  hr: 1  min: 42  sec: 14\n",
            "epoch: 1  batch: 86 / 98  loss: 0.5315354471636373  hr: 1  min: 41  sec: 58\n",
            "epoch: 1  batch: 87 / 98  loss: 0.530032442732789  hr: 1  min: 41  sec: 30\n",
            "epoch: 1  batch: 88 / 98  loss: 0.5317029165612026  hr: 1  min: 41  sec: 35\n",
            "epoch: 1  batch: 89 / 98  loss: 0.5294454993491762  hr: 1  min: 41  sec: 21\n",
            "epoch: 1  batch: 90 / 98  loss: 0.5280939776036474  hr: 1  min: 40  sec: 46\n",
            "epoch: 1  batch: 91 / 98  loss: 0.5274145369018827  hr: 1  min: 40  sec: 38\n",
            "epoch: 1  batch: 92 / 98  loss: 0.5260835634949415  hr: 1  min: 40  sec: 22\n",
            "epoch: 1  batch: 93 / 98  loss: 0.5241924942501129  hr: 1  min: 40  sec: 20\n",
            "epoch: 1  batch: 94 / 98  loss: 0.5250040858666948  hr: 1  min: 39  sec: 53\n",
            "epoch: 1  batch: 95 / 98  loss: 0.525208665979536  hr: 1  min: 39  sec: 40\n",
            "epoch: 1  batch: 96 / 98  loss: 0.5229894178919494  hr: 1  min: 39  sec: 21\n",
            "epoch: 1  batch: 97 / 98  loss: 0.5231058445480681  hr: 1  min: 39  sec: 3\n",
            "epoch: 1  batch: 98 / 98  loss: 0.5239430107936567  hr: 1  min: 38  sec: 49\n",
            "epoch: 2  batch: 1 / 98  loss: 0.45634931325912476  hr: 1  min: 37  sec: 5\n",
            "epoch: 2  batch: 2 / 98  loss: 0.4205610901117325  hr: 1  min: 53  sec: 2\n",
            "epoch: 2  batch: 3 / 98  loss: 0.37590986490249634  hr: 1  min: 44  sec: 21\n",
            "epoch: 2  batch: 4 / 98  loss: 0.3574127182364464  hr: 1  min: 40  sec: 14\n",
            "epoch: 2  batch: 5 / 98  loss: 0.3468541741371155  hr: 1  min: 44  sec: 53\n",
            "epoch: 2  batch: 6 / 98  loss: 0.36345406373341876  hr: 1  min: 45  sec: 25\n",
            "epoch: 2  batch: 7 / 98  loss: 0.3528157557759966  hr: 1  min: 42  sec: 2\n",
            "epoch: 2  batch: 8 / 98  loss: 0.328157514333725  hr: 1  min: 38  sec: 2\n",
            "epoch: 2  batch: 9 / 98  loss: 0.3120930824014876  hr: 1  min: 35  sec: 39\n",
            "epoch: 2  batch: 10 / 98  loss: 0.3325429767370224  hr: 1  min: 35  sec: 23\n",
            "epoch: 2  batch: 11 / 98  loss: 0.33091794631697913  hr: 1  min: 36  sec: 3\n",
            "epoch: 2  batch: 12 / 98  loss: 0.32496331880489987  hr: 1  min: 35  sec: 42\n",
            "epoch: 2  batch: 13 / 98  loss: 0.31777883951480573  hr: 1  min: 35  sec: 39\n",
            "epoch: 2  batch: 14 / 98  loss: 0.3135393645082201  hr: 1  min: 35  sec: 22\n",
            "epoch: 2  batch: 15 / 98  loss: 0.30730602343877156  hr: 1  min: 34  sec: 18\n",
            "epoch: 2  batch: 16 / 98  loss: 0.2941330233588815  hr: 1  min: 32  sec: 31\n",
            "epoch: 2  batch: 17 / 98  loss: 0.2889646142721176  hr: 1  min: 30  sec: 29\n",
            "epoch: 2  batch: 18 / 98  loss: 0.2923203334212303  hr: 1  min: 29  sec: 20\n",
            "epoch: 2  batch: 19 / 98  loss: 0.2945421471407539  hr: 1  min: 27  sec: 34\n",
            "epoch: 2  batch: 20 / 98  loss: 0.3033807210624218  hr: 1  min: 26  sec: 37\n",
            "epoch: 2  batch: 21 / 98  loss: 0.2964890868890853  hr: 1  min: 27  sec: 24\n",
            "epoch: 2  batch: 22 / 98  loss: 0.29220410910519684  hr: 1  min: 26  sec: 44\n",
            "epoch: 2  batch: 23 / 98  loss: 0.2975403200025144  hr: 1  min: 26  sec: 12\n",
            "epoch: 2  batch: 24 / 98  loss: 0.2903019245713949  hr: 1  min: 26  sec: 43\n",
            "epoch: 2  batch: 25 / 98  loss: 0.2886950093507767  hr: 1  min: 25  sec: 55\n",
            "epoch: 2  batch: 26 / 98  loss: 0.30119190135827434  hr: 1  min: 25  sec: 42\n",
            "epoch: 2  batch: 27 / 98  loss: 0.2951023992564943  hr: 1  min: 25  sec: 56\n",
            "epoch: 2  batch: 28 / 98  loss: 0.2907309058521475  hr: 1  min: 25  sec: 43\n",
            "epoch: 2  batch: 29 / 98  loss: 0.30392817741837996  hr: 1  min: 25  sec: 28\n",
            "epoch: 2  batch: 30 / 98  loss: 0.30113242417573927  hr: 1  min: 25  sec: 17\n",
            "epoch: 2  batch: 31 / 98  loss: 0.2941949526148458  hr: 1  min: 25  sec: 8\n",
            "epoch: 2  batch: 32 / 98  loss: 0.30090888822451234  hr: 1  min: 24  sec: 59\n",
            "epoch: 2  batch: 33 / 98  loss: 0.2988450247229952  hr: 1  min: 24  sec: 35\n",
            "epoch: 2  batch: 34 / 98  loss: 0.2975156289689681  hr: 1  min: 24  sec: 19\n",
            "epoch: 2  batch: 35 / 98  loss: 0.2929812431335449  hr: 1  min: 24  sec: 11\n",
            "epoch: 2  batch: 36 / 98  loss: 0.2912751974331008  hr: 1  min: 24  sec: 59\n",
            "epoch: 2  batch: 37 / 98  loss: 0.29238659948916046  hr: 1  min: 25  sec: 28\n",
            "epoch: 2  batch: 38 / 98  loss: 0.2911541030595177  hr: 1  min: 25  sec: 51\n",
            "epoch: 2  batch: 39 / 98  loss: 0.2899645899350827  hr: 1  min: 25  sec: 18\n",
            "epoch: 2  batch: 40 / 98  loss: 0.2985347371548414  hr: 1  min: 25  sec: 40\n",
            "epoch: 2  batch: 41 / 98  loss: 0.29545858902175254  hr: 1  min: 25  sec: 53\n",
            "epoch: 2  batch: 42 / 98  loss: 0.30281801486299154  hr: 1  min: 25  sec: 2\n",
            "epoch: 2  batch: 43 / 98  loss: 0.29845301980196043  hr: 1  min: 25  sec: 35\n",
            "epoch: 2  batch: 44 / 98  loss: 0.29619418355551635  hr: 1  min: 25  sec: 17\n",
            "epoch: 2  batch: 45 / 98  loss: 0.2905933585431841  hr: 1  min: 25  sec: 10\n",
            "epoch: 2  batch: 46 / 98  loss: 0.2955104235721671  hr: 1  min: 24  sec: 27\n",
            "epoch: 2  batch: 47 / 98  loss: 0.2987061821399851  hr: 1  min: 23  sec: 43\n",
            "epoch: 2  batch: 48 / 98  loss: 0.30038688828547794  hr: 1  min: 23  sec: 29\n",
            "epoch: 2  batch: 49 / 98  loss: 0.3048114436013358  hr: 1  min: 23  sec: 8\n",
            "epoch: 2  batch: 50 / 98  loss: 0.30716661632061004  hr: 1  min: 23  sec: 8\n",
            "epoch: 2  batch: 51 / 98  loss: 0.30277712175659105  hr: 1  min: 22  sec: 32\n",
            "epoch: 2  batch: 52 / 98  loss: 0.3014714073103208  hr: 1  min: 22  sec: 18\n",
            "epoch: 2  batch: 53 / 98  loss: 0.30010243969143563  hr: 1  min: 21  sec: 41\n",
            "epoch: 2  batch: 54 / 98  loss: 0.2998974720637004  hr: 1  min: 21  sec: 13\n",
            "epoch: 2  batch: 55 / 98  loss: 0.3015502685850317  hr: 1  min: 20  sec: 59\n",
            "epoch: 2  batch: 56 / 98  loss: 0.3012462157223906  hr: 1  min: 20  sec: 48\n",
            "epoch: 2  batch: 57 / 98  loss: 0.3032250446185731  hr: 1  min: 20  sec: 25\n",
            "epoch: 2  batch: 58 / 98  loss: 0.3027777949283863  hr: 1  min: 20  sec: 11\n",
            "epoch: 2  batch: 59 / 98  loss: 0.30533682491819736  hr: 1  min: 19  sec: 51\n",
            "epoch: 2  batch: 60 / 98  loss: 0.3036121817926566  hr: 1  min: 19  sec: 21\n",
            "epoch: 2  batch: 61 / 98  loss: 0.3059118612379324  hr: 1  min: 19  sec: 22\n",
            "epoch: 2  batch: 62 / 98  loss: 0.30516477626177574  hr: 1  min: 19  sec: 29\n",
            "epoch: 2  batch: 63 / 98  loss: 0.3059296544109072  hr: 1  min: 19  sec: 21\n",
            "epoch: 2  batch: 64 / 98  loss: 0.306572885485366  hr: 1  min: 18  sec: 56\n",
            "epoch: 2  batch: 65 / 98  loss: 0.30321795963324033  hr: 1  min: 18  sec: 17\n",
            "epoch: 2  batch: 66 / 98  loss: 0.3034119057384404  hr: 1  min: 18  sec: 6\n",
            "epoch: 2  batch: 67 / 98  loss: 0.30262061708898685  hr: 1  min: 18  sec: 2\n",
            "epoch: 2  batch: 68 / 98  loss: 0.30420486607095776  hr: 1  min: 17  sec: 48\n",
            "epoch: 2  batch: 69 / 98  loss: 0.30285691523897473  hr: 1  min: 17  sec: 44\n",
            "epoch: 2  batch: 70 / 98  loss: 0.3030841601746423  hr: 1  min: 17  sec: 23\n",
            "epoch: 2  batch: 71 / 98  loss: 0.3039032745529229  hr: 1  min: 17  sec: 18\n",
            "epoch: 2  batch: 72 / 98  loss: 0.30662225517961716  hr: 1  min: 17  sec: 9\n",
            "epoch: 2  batch: 73 / 98  loss: 0.30605582260105707  hr: 1  min: 16  sec: 40\n",
            "epoch: 2  batch: 74 / 98  loss: 0.3085312319768442  hr: 1  min: 16  sec: 27\n",
            "epoch: 2  batch: 75 / 98  loss: 0.3076025313138962  hr: 1  min: 16  sec: 18\n",
            "epoch: 2  batch: 76 / 98  loss: 0.31035383300561653  hr: 1  min: 15  sec: 50\n",
            "epoch: 2  batch: 77 / 98  loss: 0.31668770797066875  hr: 1  min: 15  sec: 36\n",
            "epoch: 2  batch: 78 / 98  loss: 0.31978465215517926  hr: 1  min: 15  sec: 21\n",
            "epoch: 2  batch: 79 / 98  loss: 0.320347672210464  hr: 1  min: 15  sec: 16\n",
            "epoch: 2  batch: 80 / 98  loss: 0.32007587533444165  hr: 1  min: 14  sec: 58\n",
            "epoch: 2  batch: 81 / 98  loss: 0.32262943464296834  hr: 1  min: 14  sec: 41\n",
            "epoch: 2  batch: 82 / 98  loss: 0.3237988779821047  hr: 1  min: 14  sec: 29\n",
            "epoch: 2  batch: 83 / 98  loss: 0.32465697178639563  hr: 1  min: 14  sec: 28\n",
            "epoch: 2  batch: 84 / 98  loss: 0.322575371889841  hr: 1  min: 14  sec: 8\n",
            "epoch: 2  batch: 85 / 98  loss: 0.3211261326775831  hr: 1  min: 13  sec: 40\n",
            "epoch: 2  batch: 86 / 98  loss: 0.3205427962333657  hr: 1  min: 13  sec: 30\n",
            "epoch: 2  batch: 87 / 98  loss: 0.32407214638145493  hr: 1  min: 13  sec: 8\n",
            "epoch: 2  batch: 88 / 98  loss: 0.3246084910563447  hr: 1  min: 12  sec: 51\n",
            "epoch: 2  batch: 89 / 98  loss: 0.32464303109752995  hr: 1  min: 12  sec: 34\n",
            "epoch: 2  batch: 90 / 98  loss: 0.32339402933915457  hr: 1  min: 12  sec: 22\n",
            "epoch: 2  batch: 91 / 98  loss: 0.32646091331492416  hr: 1  min: 12  sec: 9\n",
            "epoch: 2  batch: 92 / 98  loss: 0.32716134579285333  hr: 1  min: 11  sec: 50\n",
            "epoch: 2  batch: 93 / 98  loss: 0.3275922562486382  hr: 1  min: 11  sec: 35\n",
            "epoch: 2  batch: 94 / 98  loss: 0.32754891476732617  hr: 1  min: 11  sec: 23\n",
            "epoch: 2  batch: 95 / 98  loss: 0.3281085346874438  hr: 1  min: 11  sec: 5\n",
            "epoch: 2  batch: 96 / 98  loss: 0.3261460840391616  hr: 1  min: 10  sec: 58\n",
            "epoch: 2  batch: 97 / 98  loss: 0.3272650409297845  hr: 1  min: 10  sec: 44\n",
            "epoch: 2  batch: 98 / 98  loss: 0.3299054498879277  hr: 1  min: 10  sec: 28\n",
            "epoch: 3  batch: 1 / 98  loss: 0.23760569095611572  hr: 1  min: 39  sec: 25\n",
            "epoch: 3  batch: 2 / 98  loss: 0.25982528924942017  hr: 1  min: 11  sec: 57\n",
            "epoch: 3  batch: 3 / 98  loss: 0.2331522156794866  hr: 1  min: 15  sec: 24\n",
            "epoch: 3  batch: 4 / 98  loss: 0.23477356508374214  hr: 1  min: 11  sec: 59\n",
            "epoch: 3  batch: 5 / 98  loss: 0.2182701826095581  hr: 1  min: 12  sec: 32\n",
            "epoch: 3  batch: 6 / 98  loss: 0.21262343227863312  hr: 1  min: 12  sec: 20\n",
            "epoch: 3  batch: 7 / 98  loss: 0.2163302174636296  hr: 1  min: 11  sec: 13\n",
            "epoch: 3  batch: 8 / 98  loss: 0.20571526512503624  hr: 1  min: 10  sec: 10\n",
            "epoch: 3  batch: 9 / 98  loss: 0.19985395835505593  hr: 1  min: 10  sec: 18\n",
            "epoch: 3  batch: 10 / 98  loss: 0.19021628201007842  hr: 1  min: 8  sec: 57\n",
            "epoch: 3  batch: 11 / 98  loss: 0.18989326737143777  hr: 1  min: 6  sec: 14\n",
            "epoch: 3  batch: 12 / 98  loss: 0.18357113127907118  hr: 1  min: 6  sec: 2\n",
            "epoch: 3  batch: 13 / 98  loss: 0.17900512252862638  hr: 1  min: 6  sec: 33\n",
            "epoch: 3  batch: 14 / 98  loss: 0.16990719602576324  hr: 1  min: 5  sec: 5\n",
            "epoch: 3  batch: 15 / 98  loss: 0.17605739310383797  hr: 1  min: 3  sec: 56\n",
            "epoch: 3  batch: 16 / 98  loss: 0.18395538884215057  hr: 1  min: 3  sec: 41\n",
            "epoch: 3  batch: 17 / 98  loss: 0.17793899314368472  hr: 1  min: 2  sec: 45\n",
            "epoch: 3  batch: 18 / 98  loss: 0.1832230577452315  hr: 1  min: 2  sec: 12\n",
            "epoch: 3  batch: 19 / 98  loss: 0.18307287814585785  hr: 1  min: 1  sec: 40\n",
            "epoch: 3  batch: 20 / 98  loss: 0.18321557845920325  hr: 1  min: 1  sec: 57\n",
            "epoch: 3  batch: 21 / 98  loss: 0.17778585478663445  hr: 1  min: 2  sec: 34\n",
            "epoch: 3  batch: 22 / 98  loss: 0.1816609947180206  hr: 1  min: 2  sec: 32\n",
            "epoch: 3  batch: 23 / 98  loss: 0.17623798565372176  hr: 1  min: 2  sec: 4\n",
            "epoch: 3  batch: 24 / 98  loss: 0.17945152102038264  hr: 1  min: 1  sec: 34\n",
            "epoch: 3  batch: 25 / 98  loss: 0.18067135587334632  hr: 1  min: 1  sec: 52\n",
            "epoch: 3  batch: 26 / 98  loss: 0.1847184943751647  hr: 1  min: 1  sec: 18\n",
            "epoch: 3  batch: 27 / 98  loss: 0.18165613779867137  hr: 1  min: 0  sec: 24\n",
            "epoch: 3  batch: 28 / 98  loss: 0.1773378471178668  hr: 0  min: 59  sec: 41\n",
            "epoch: 3  batch: 29 / 98  loss: 0.17692102337705679  hr: 0  min: 59  sec: 59\n",
            "epoch: 3  batch: 30 / 98  loss: 0.17839388797680536  hr: 0  min: 59  sec: 41\n",
            "epoch: 3  batch: 31 / 98  loss: 0.17507212801325706  hr: 0  min: 59  sec: 6\n",
            "epoch: 3  batch: 32 / 98  loss: 0.1716760213021189  hr: 0  min: 58  sec: 59\n",
            "epoch: 3  batch: 33 / 98  loss: 0.1707393673784805  hr: 0  min: 58  sec: 31\n",
            "epoch: 3  batch: 34 / 98  loss: 0.17905090508215568  hr: 0  min: 58  sec: 47\n",
            "epoch: 3  batch: 35 / 98  loss: 0.17808012813329696  hr: 0  min: 58  sec: 36\n",
            "epoch: 3  batch: 36 / 98  loss: 0.18029629790948498  hr: 0  min: 58  sec: 12\n",
            "epoch: 3  batch: 37 / 98  loss: 0.17831944875620506  hr: 0  min: 57  sec: 56\n",
            "epoch: 3  batch: 38 / 98  loss: 0.1779016301428017  hr: 0  min: 58  sec: 11\n",
            "epoch: 3  batch: 39 / 98  loss: 0.17930327374965715  hr: 0  min: 58  sec: 0\n",
            "epoch: 3  batch: 40 / 98  loss: 0.17653840277343988  hr: 0  min: 57  sec: 18\n",
            "epoch: 3  batch: 41 / 98  loss: 0.1763919390192846  hr: 0  min: 57  sec: 19\n",
            "epoch: 3  batch: 42 / 98  loss: 0.17315921151921862  hr: 0  min: 56  sec: 59\n",
            "epoch: 3  batch: 43 / 98  loss: 0.17249619995438775  hr: 0  min: 56  sec: 48\n",
            "epoch: 3  batch: 44 / 98  loss: 0.17061165110631424  hr: 0  min: 56  sec: 29\n",
            "epoch: 3  batch: 45 / 98  loss: 0.16867953555451498  hr: 0  min: 56  sec: 11\n",
            "epoch: 3  batch: 46 / 98  loss: 0.16843209982566212  hr: 0  min: 55  sec: 40\n",
            "epoch: 3  batch: 47 / 98  loss: 0.1747780627709754  hr: 0  min: 55  sec: 56\n",
            "epoch: 3  batch: 48 / 98  loss: 0.17581385637943944  hr: 0  min: 55  sec: 43\n",
            "epoch: 3  batch: 49 / 98  loss: 0.17295910539675732  hr: 0  min: 55  sec: 27\n",
            "epoch: 3  batch: 50 / 98  loss: 0.17264172166585923  hr: 0  min: 55  sec: 20\n",
            "epoch: 3  batch: 51 / 98  loss: 0.17076659334056518  hr: 0  min: 55  sec: 4\n",
            "epoch: 3  batch: 52 / 98  loss: 0.17590371590967363  hr: 0  min: 54  sec: 42\n",
            "epoch: 3  batch: 53 / 98  loss: 0.17495000629492527  hr: 0  min: 54  sec: 30\n",
            "epoch: 3  batch: 54 / 98  loss: 0.17710558449228606  hr: 0  min: 54  sec: 34\n",
            "epoch: 3  batch: 55 / 98  loss: 0.17710883874784816  hr: 0  min: 54  sec: 5\n",
            "epoch: 3  batch: 56 / 98  loss: 0.17506903636136226  hr: 0  min: 54  sec: 0\n",
            "epoch: 3  batch: 57 / 98  loss: 0.1726843338917222  hr: 0  min: 53  sec: 42\n",
            "epoch: 3  batch: 58 / 98  loss: 0.17082188169247117  hr: 0  min: 53  sec: 41\n",
            "epoch: 3  batch: 59 / 98  loss: 0.169474583245435  hr: 0  min: 53  sec: 14\n",
            "epoch: 3  batch: 60 / 98  loss: 0.17324311801542838  hr: 0  min: 53  sec: 9\n",
            "epoch: 3  batch: 61 / 98  loss: 0.17084124342339937  hr: 0  min: 52  sec: 49\n",
            "epoch: 3  batch: 62 / 98  loss: 0.17386480589066783  hr: 0  min: 52  sec: 25\n",
            "epoch: 3  batch: 63 / 98  loss: 0.1743026224393693  hr: 0  min: 52  sec: 14\n",
            "epoch: 3  batch: 64 / 98  loss: 0.18151320610195398  hr: 0  min: 51  sec: 54\n",
            "epoch: 3  batch: 65 / 98  loss: 0.1823386740226012  hr: 0  min: 51  sec: 32\n",
            "epoch: 3  batch: 66 / 98  loss: 0.18279470322710095  hr: 0  min: 51  sec: 14\n",
            "epoch: 3  batch: 67 / 98  loss: 0.1823482842587713  hr: 0  min: 50  sec: 57\n",
            "epoch: 3  batch: 68 / 98  loss: 0.1848576108322424  hr: 0  min: 50  sec: 46\n",
            "epoch: 3  batch: 69 / 98  loss: 0.1832873086998428  hr: 0  min: 50  sec: 35\n",
            "epoch: 3  batch: 70 / 98  loss: 0.18713342930589402  hr: 0  min: 50  sec: 31\n",
            "epoch: 3  batch: 71 / 98  loss: 0.18491489970138375  hr: 0  min: 50  sec: 18\n",
            "epoch: 3  batch: 72 / 98  loss: 0.18385694967582822  hr: 0  min: 49  sec: 56\n",
            "epoch: 3  batch: 73 / 98  loss: 0.18189398326898273  hr: 0  min: 49  sec: 40\n",
            "epoch: 3  batch: 74 / 98  loss: 0.1842716869369552  hr: 0  min: 49  sec: 44\n",
            "epoch: 3  batch: 75 / 98  loss: 0.1849073359866937  hr: 0  min: 49  sec: 32\n",
            "epoch: 3  batch: 76 / 98  loss: 0.18677883766787617  hr: 0  min: 49  sec: 26\n",
            "epoch: 3  batch: 77 / 98  loss: 0.18968936505836326  hr: 0  min: 49  sec: 19\n",
            "epoch: 3  batch: 78 / 98  loss: 0.18975467707675236  hr: 0  min: 49  sec: 2\n",
            "epoch: 3  batch: 79 / 98  loss: 0.1882229742087141  hr: 0  min: 48  sec: 47\n",
            "epoch: 3  batch: 80 / 98  loss: 0.1885864630807191  hr: 0  min: 48  sec: 38\n",
            "epoch: 3  batch: 81 / 98  loss: 0.19165184693755927  hr: 0  min: 48  sec: 23\n",
            "epoch: 3  batch: 82 / 98  loss: 0.19101853273445513  hr: 0  min: 48  sec: 8\n",
            "epoch: 3  batch: 83 / 98  loss: 0.19407504981002174  hr: 0  min: 47  sec: 54\n",
            "epoch: 3  batch: 84 / 98  loss: 0.1928395933604666  hr: 0  min: 48  sec: 2\n",
            "epoch: 3  batch: 85 / 98  loss: 0.19535159885006792  hr: 0  min: 47  sec: 52\n",
            "epoch: 3  batch: 86 / 98  loss: 0.1937698435124963  hr: 0  min: 47  sec: 45\n",
            "epoch: 3  batch: 87 / 98  loss: 0.19566453025601377  hr: 0  min: 47  sec: 41\n",
            "epoch: 3  batch: 88 / 98  loss: 0.1970981014892459  hr: 0  min: 47  sec: 30\n",
            "epoch: 3  batch: 89 / 98  loss: 0.19543393307857299  hr: 0  min: 47  sec: 15\n",
            "epoch: 3  batch: 90 / 98  loss: 0.19466746813721128  hr: 0  min: 47  sec: 0\n",
            "epoch: 3  batch: 91 / 98  loss: 0.19549507197442945  hr: 0  min: 46  sec: 47\n",
            "epoch: 3  batch: 92 / 98  loss: 0.19412190054097903  hr: 0  min: 46  sec: 29\n",
            "epoch: 3  batch: 93 / 98  loss: 0.1923740594297327  hr: 0  min: 46  sec: 8\n",
            "epoch: 3  batch: 94 / 98  loss: 0.19324010150863768  hr: 0  min: 45  sec: 52\n",
            "epoch: 3  batch: 95 / 98  loss: 0.1932795126187174  hr: 0  min: 45  sec: 45\n",
            "epoch: 3  batch: 96 / 98  loss: 0.19527472524593273  hr: 0  min: 45  sec: 30\n",
            "epoch: 3  batch: 97 / 98  loss: 0.19878994834791755  hr: 0  min: 45  sec: 13\n",
            "epoch: 3  batch: 98 / 98  loss: 0.20122749008694474  hr: 0  min: 45  sec: 0\n",
            "epoch: 4  batch: 1 / 98  loss: 0.1718704104423523  hr: 1  min: 3  sec: 15\n",
            "epoch: 4  batch: 2 / 98  loss: 0.11710385605692863  hr: 0  min: 48  sec: 29\n",
            "epoch: 4  batch: 3 / 98  loss: 0.10406782974799474  hr: 0  min: 42  sec: 1\n",
            "epoch: 4  batch: 4 / 98  loss: 0.10267054848372936  hr: 0  min: 42  sec: 14\n",
            "epoch: 4  batch: 5 / 98  loss: 0.12390779703855515  hr: 0  min: 41  sec: 7\n",
            "epoch: 4  batch: 6 / 98  loss: 0.1254542109866937  hr: 0  min: 40  sec: 24\n",
            "epoch: 4  batch: 7 / 98  loss: 0.11709143327815193  hr: 0  min: 41  sec: 7\n",
            "epoch: 4  batch: 8 / 98  loss: 0.11410489771515131  hr: 0  min: 41  sec: 3\n",
            "epoch: 4  batch: 9 / 98  loss: 0.11484692990779877  hr: 0  min: 40  sec: 34\n",
            "epoch: 4  batch: 10 / 98  loss: 0.10781269408762455  hr: 0  min: 39  sec: 58\n",
            "epoch: 4  batch: 11 / 98  loss: 0.10931443524631587  hr: 0  min: 38  sec: 39\n",
            "epoch: 4  batch: 12 / 98  loss: 0.10652974713593721  hr: 0  min: 38  sec: 41\n",
            "epoch: 4  batch: 13 / 98  loss: 0.10064092249824451  hr: 0  min: 39  sec: 15\n",
            "epoch: 4  batch: 14 / 98  loss: 0.09727397241762706  hr: 0  min: 39  sec: 19\n",
            "epoch: 4  batch: 15 / 98  loss: 0.0967684139808019  hr: 0  min: 39  sec: 1\n",
            "epoch: 4  batch: 16 / 98  loss: 0.09690017066895962  hr: 0  min: 38  sec: 58\n",
            "epoch: 4  batch: 17 / 98  loss: 0.09529350566513398  hr: 0  min: 38  sec: 29\n",
            "epoch: 4  batch: 18 / 98  loss: 0.09707860358887249  hr: 0  min: 38  sec: 58\n",
            "epoch: 4  batch: 19 / 98  loss: 0.0954131197772528  hr: 0  min: 39  sec: 1\n",
            "epoch: 4  batch: 20 / 98  loss: 0.10482753030955791  hr: 0  min: 38  sec: 24\n",
            "epoch: 4  batch: 21 / 98  loss: 0.10420177983386177  hr: 0  min: 38  sec: 7\n",
            "epoch: 4  batch: 22 / 98  loss: 0.10131648927927017  hr: 0  min: 38  sec: 3\n",
            "epoch: 4  batch: 23 / 98  loss: 0.10034867246513782  hr: 0  min: 38  sec: 55\n",
            "epoch: 4  batch: 24 / 98  loss: 0.09761503462990125  hr: 0  min: 38  sec: 37\n",
            "epoch: 4  batch: 25 / 98  loss: 0.09581744953989983  hr: 0  min: 38  sec: 21\n",
            "epoch: 4  batch: 26 / 98  loss: 0.10151330768488921  hr: 0  min: 38  sec: 5\n",
            "epoch: 4  batch: 27 / 98  loss: 0.09958013036736736  hr: 0  min: 38  sec: 3\n",
            "epoch: 4  batch: 28 / 98  loss: 0.10700422977762562  hr: 0  min: 37  sec: 45\n",
            "epoch: 4  batch: 29 / 98  loss: 0.10450385164084106  hr: 0  min: 37  sec: 26\n",
            "epoch: 4  batch: 30 / 98  loss: 0.10422669462859631  hr: 0  min: 37  sec: 31\n",
            "epoch: 4  batch: 31 / 98  loss: 0.10261443113127063  hr: 0  min: 37  sec: 23\n",
            "epoch: 4  batch: 32 / 98  loss: 0.10355524392798543  hr: 0  min: 37  sec: 14\n",
            "epoch: 4  batch: 33 / 98  loss: 0.10375065446803064  hr: 0  min: 37  sec: 1\n",
            "epoch: 4  batch: 34 / 98  loss: 0.107922492439256  hr: 0  min: 36  sec: 53\n",
            "epoch: 4  batch: 35 / 98  loss: 0.10894939111811774  hr: 0  min: 36  sec: 46\n",
            "epoch: 4  batch: 36 / 98  loss: 0.10961344444917308  hr: 0  min: 36  sec: 32\n",
            "epoch: 4  batch: 37 / 98  loss: 0.10773053322289441  hr: 0  min: 36  sec: 19\n",
            "epoch: 4  batch: 38 / 98  loss: 0.10739325045755035  hr: 0  min: 36  sec: 16\n",
            "epoch: 4  batch: 39 / 98  loss: 0.10706751258709492  hr: 0  min: 36  sec: 6\n",
            "epoch: 4  batch: 40 / 98  loss: 0.11127851400524377  hr: 0  min: 35  sec: 58\n",
            "epoch: 4  batch: 41 / 98  loss: 0.11097211772348822  hr: 0  min: 35  sec: 54\n",
            "epoch: 4  batch: 42 / 98  loss: 0.10957980031768481  hr: 0  min: 35  sec: 51\n",
            "epoch: 4  batch: 43 / 98  loss: 0.11241906552120697  hr: 0  min: 35  sec: 42\n",
            "epoch: 4  batch: 44 / 98  loss: 0.11242878606373613  hr: 0  min: 35  sec: 31\n",
            "epoch: 4  batch: 45 / 98  loss: 0.11341142621305254  hr: 0  min: 35  sec: 25\n",
            "epoch: 4  batch: 46 / 98  loss: 0.11419614728378213  hr: 0  min: 35  sec: 15\n",
            "epoch: 4  batch: 47 / 98  loss: 0.11357199955493846  hr: 0  min: 34  sec: 56\n",
            "epoch: 4  batch: 48 / 98  loss: 0.11637714070578416  hr: 0  min: 34  sec: 41\n",
            "epoch: 4  batch: 49 / 98  loss: 0.11439108840969144  hr: 0  min: 34  sec: 23\n",
            "epoch: 4  batch: 50 / 98  loss: 0.11411212719976901  hr: 0  min: 34  sec: 24\n",
            "epoch: 4  batch: 51 / 98  loss: 0.1131459318977945  hr: 0  min: 34  sec: 6\n",
            "epoch: 4  batch: 52 / 98  loss: 0.11378157188972601  hr: 0  min: 33  sec: 50\n",
            "epoch: 4  batch: 53 / 98  loss: 0.11407445279775925  hr: 0  min: 33  sec: 29\n",
            "epoch: 4  batch: 54 / 98  loss: 0.1132428486728006  hr: 0  min: 33  sec: 8\n",
            "epoch: 4  batch: 55 / 98  loss: 0.11341581473296339  hr: 0  min: 32  sec: 49\n",
            "epoch: 4  batch: 56 / 98  loss: 0.11190177483617195  hr: 0  min: 32  sec: 43\n",
            "epoch: 4  batch: 57 / 98  loss: 0.11319416013072457  hr: 0  min: 32  sec: 33\n",
            "epoch: 4  batch: 58 / 98  loss: 0.1127096732821444  hr: 0  min: 32  sec: 29\n",
            "epoch: 4  batch: 59 / 98  loss: 0.1138518538199744  hr: 0  min: 32  sec: 6\n",
            "epoch: 4  batch: 60 / 98  loss: 0.11309055993333458  hr: 0  min: 31  sec: 58\n",
            "epoch: 4  batch: 61 / 98  loss: 0.11155622684564746  hr: 0  min: 31  sec: 44\n",
            "epoch: 4  batch: 62 / 98  loss: 0.11001075804233551  hr: 0  min: 31  sec: 30\n",
            "epoch: 4  batch: 63 / 98  loss: 0.1115291669728264  hr: 0  min: 31  sec: 16\n",
            "epoch: 4  batch: 64 / 98  loss: 0.10991478603682481  hr: 0  min: 30  sec: 56\n",
            "epoch: 4  batch: 65 / 98  loss: 0.10893638910582433  hr: 0  min: 30  sec: 35\n",
            "epoch: 4  batch: 66 / 98  loss: 0.10924501894888553  hr: 0  min: 30  sec: 28\n",
            "epoch: 4  batch: 67 / 98  loss: 0.10786426134073912  hr: 0  min: 30  sec: 17\n",
            "epoch: 4  batch: 68 / 98  loss: 0.10866258446784581  hr: 0  min: 30  sec: 11\n",
            "epoch: 4  batch: 69 / 98  loss: 0.1074557105700175  hr: 0  min: 29  sec: 56\n",
            "epoch: 4  batch: 70 / 98  loss: 0.10972061668123517  hr: 0  min: 29  sec: 36\n",
            "epoch: 4  batch: 71 / 98  loss: 0.11323135041854751  hr: 0  min: 29  sec: 27\n",
            "epoch: 4  batch: 72 / 98  loss: 0.11190420735834374  hr: 0  min: 29  sec: 16\n",
            "epoch: 4  batch: 73 / 98  loss: 0.11157624224481517  hr: 0  min: 28  sec: 55\n",
            "epoch: 4  batch: 74 / 98  loss: 0.1105437565695595  hr: 0  min: 28  sec: 40\n",
            "epoch: 4  batch: 75 / 98  loss: 0.11069197734196981  hr: 0  min: 28  sec: 23\n",
            "epoch: 4  batch: 76 / 98  loss: 0.11389154940843582  hr: 0  min: 28  sec: 10\n",
            "epoch: 4  batch: 77 / 98  loss: 0.11386124334939114  hr: 0  min: 27  sec: 50\n",
            "epoch: 4  batch: 78 / 98  loss: 0.1137362477871088  hr: 0  min: 27  sec: 30\n",
            "epoch: 4  batch: 79 / 98  loss: 0.11536052558995501  hr: 0  min: 27  sec: 18\n",
            "epoch: 4  batch: 80 / 98  loss: 0.1166659265756607  hr: 0  min: 27  sec: 1\n",
            "epoch: 4  batch: 81 / 98  loss: 0.11632633338003982  hr: 0  min: 26  sec: 45\n",
            "epoch: 4  batch: 82 / 98  loss: 0.11531799877198731  hr: 0  min: 26  sec: 37\n",
            "epoch: 4  batch: 83 / 98  loss: 0.11516027538532234  hr: 0  min: 26  sec: 22\n",
            "epoch: 4  batch: 84 / 98  loss: 0.11620805297224295  hr: 0  min: 26  sec: 9\n",
            "epoch: 4  batch: 85 / 98  loss: 0.11764035338864606  hr: 0  min: 25  sec: 54\n",
            "epoch: 4  batch: 86 / 98  loss: 0.11661444515596296  hr: 0  min: 25  sec: 43\n",
            "epoch: 4  batch: 87 / 98  loss: 0.1157262144374779  hr: 0  min: 25  sec: 25\n",
            "epoch: 4  batch: 88 / 98  loss: 0.11468781232410534  hr: 0  min: 25  sec: 10\n",
            "epoch: 4  batch: 89 / 98  loss: 0.11570196981761563  hr: 0  min: 24  sec: 54\n",
            "epoch: 4  batch: 90 / 98  loss: 0.1148073227248258  hr: 0  min: 24  sec: 39\n",
            "epoch: 4  batch: 91 / 98  loss: 0.11700917970757563  hr: 0  min: 24  sec: 22\n",
            "epoch: 4  batch: 92 / 98  loss: 0.11601817370999766  hr: 0  min: 24  sec: 9\n",
            "epoch: 4  batch: 93 / 98  loss: 0.11609585701377802  hr: 0  min: 23  sec: 53\n",
            "epoch: 4  batch: 94 / 98  loss: 0.11541760362129896  hr: 0  min: 23  sec: 42\n",
            "epoch: 4  batch: 95 / 98  loss: 0.11552298114095863  hr: 0  min: 23  sec: 29\n",
            "epoch: 4  batch: 96 / 98  loss: 0.11471654356379683  hr: 0  min: 23  sec: 15\n",
            "epoch: 4  batch: 97 / 98  loss: 0.11586418815110762  hr: 0  min: 23  sec: 2\n",
            "epoch: 4  batch: 98 / 98  loss: 0.1149972369134122  hr: 0  min: 22  sec: 48\n",
            "epoch: 5  batch: 1 / 98  loss: 0.025960484519600868  hr: 0  min: 32  sec: 20\n",
            "epoch: 5  batch: 2 / 98  loss: 0.03125871252268553  hr: 0  min: 26  sec: 54\n",
            "epoch: 5  batch: 3 / 98  loss: 0.07022865302860737  hr: 0  min: 24  sec: 18\n",
            "epoch: 5  batch: 4 / 98  loss: 0.06894786050543189  hr: 0  min: 24  sec: 21\n",
            "epoch: 5  batch: 5 / 98  loss: 0.06610053740441799  hr: 0  min: 24  sec: 9\n",
            "epoch: 5  batch: 6 / 98  loss: 0.0775452700133125  hr: 0  min: 24  sec: 6\n",
            "epoch: 5  batch: 7 / 98  loss: 0.07244815012173993  hr: 0  min: 23  sec: 18\n",
            "epoch: 5  batch: 8 / 98  loss: 0.06598156644031405  hr: 0  min: 23  sec: 15\n",
            "epoch: 5  batch: 9 / 98  loss: 0.06663335487246513  hr: 0  min: 22  sec: 28\n",
            "epoch: 5  batch: 10 / 98  loss: 0.06170257329940796  hr: 0  min: 22  sec: 17\n",
            "epoch: 5  batch: 11 / 98  loss: 0.0604727566242218  hr: 0  min: 22  sec: 5\n",
            "epoch: 5  batch: 12 / 98  loss: 0.06718274454275767  hr: 0  min: 22  sec: 31\n",
            "epoch: 5  batch: 13 / 98  loss: 0.06932523330816856  hr: 0  min: 21  sec: 42\n",
            "epoch: 5  batch: 14 / 98  loss: 0.065909145266882  hr: 0  min: 21  sec: 13\n",
            "epoch: 5  batch: 15 / 98  loss: 0.06209474603335063  hr: 0  min: 20  sec: 56\n",
            "epoch: 5  batch: 16 / 98  loss: 0.05997848266270012  hr: 0  min: 20  sec: 41\n",
            "epoch: 5  batch: 17 / 98  loss: 0.06625757004846544  hr: 0  min: 20  sec: 15\n",
            "epoch: 5  batch: 18 / 98  loss: 0.06599191524502304  hr: 0  min: 19  sec: 55\n",
            "epoch: 5  batch: 19 / 98  loss: 0.06314295897946547  hr: 0  min: 19  sec: 32\n",
            "epoch: 5  batch: 20 / 98  loss: 0.06044248561374843  hr: 0  min: 19  sec: 7\n",
            "epoch: 5  batch: 21 / 98  loss: 0.05827813790667625  hr: 0  min: 18  sec: 54\n",
            "epoch: 5  batch: 22 / 98  loss: 0.05640101068737832  hr: 0  min: 18  sec: 39\n",
            "epoch: 5  batch: 23 / 98  loss: 0.05837777880546839  hr: 0  min: 18  sec: 24\n",
            "epoch: 5  batch: 24 / 98  loss: 0.05715847612979511  hr: 0  min: 18  sec: 14\n",
            "epoch: 5  batch: 25 / 98  loss: 0.05526226915419102  hr: 0  min: 17  sec: 48\n",
            "epoch: 5  batch: 26 / 98  loss: 0.05636440081378588  hr: 0  min: 17  sec: 34\n",
            "epoch: 5  batch: 27 / 98  loss: 0.05638640574007123  hr: 0  min: 17  sec: 13\n",
            "epoch: 5  batch: 28 / 98  loss: 0.05471590753378613  hr: 0  min: 16  sec: 53\n",
            "epoch: 5  batch: 29 / 98  loss: 0.05834487909129981  hr: 0  min: 16  sec: 40\n",
            "epoch: 5  batch: 30 / 98  loss: 0.0579317582771182  hr: 0  min: 16  sec: 17\n",
            "epoch: 5  batch: 31 / 98  loss: 0.056473299740783627  hr: 0  min: 16  sec: 11\n",
            "epoch: 5  batch: 32 / 98  loss: 0.056695912848226726  hr: 0  min: 15  sec: 54\n",
            "epoch: 5  batch: 33 / 98  loss: 0.0554487615202864  hr: 0  min: 15  sec: 40\n",
            "epoch: 5  batch: 34 / 98  loss: 0.05605120433713583  hr: 0  min: 15  sec: 21\n",
            "epoch: 5  batch: 35 / 98  loss: 0.05622499758111579  hr: 0  min: 14  sec: 57\n",
            "epoch: 5  batch: 36 / 98  loss: 0.06087071244190964  hr: 0  min: 14  sec: 38\n",
            "epoch: 5  batch: 37 / 98  loss: 0.05967266351689358  hr: 0  min: 14  sec: 29\n",
            "epoch: 5  batch: 38 / 98  loss: 0.05833241417023696  hr: 0  min: 14  sec: 16\n",
            "epoch: 5  batch: 39 / 98  loss: 0.06101799273911195  hr: 0  min: 14  sec: 0\n",
            "epoch: 5  batch: 40 / 98  loss: 0.059861991507932547  hr: 0  min: 13  sec: 48\n",
            "epoch: 5  batch: 41 / 98  loss: 0.0585455332723696  hr: 0  min: 13  sec: 32\n",
            "epoch: 5  batch: 42 / 98  loss: 0.05733012668566689  hr: 0  min: 13  sec: 16\n",
            "epoch: 5  batch: 43 / 98  loss: 0.05718770167292204  hr: 0  min: 13  sec: 8\n",
            "epoch: 5  batch: 44 / 98  loss: 0.056265535203486004  hr: 0  min: 12  sec: 52\n",
            "epoch: 5  batch: 45 / 98  loss: 0.05552169766484035  hr: 0  min: 12  sec: 39\n",
            "epoch: 5  batch: 46 / 98  loss: 0.05509506484858044  hr: 0  min: 12  sec: 26\n",
            "epoch: 5  batch: 47 / 98  loss: 0.05445418981438939  hr: 0  min: 12  sec: 16\n",
            "epoch: 5  batch: 48 / 98  loss: 0.05630357453871208  hr: 0  min: 12  sec: 1\n",
            "epoch: 5  batch: 49 / 98  loss: 0.057451505736656944  hr: 0  min: 11  sec: 47\n",
            "epoch: 5  batch: 50 / 98  loss: 0.05691759965382517  hr: 0  min: 11  sec: 30\n",
            "epoch: 5  batch: 51 / 98  loss: 0.05602794205404672  hr: 0  min: 11  sec: 15\n",
            "epoch: 5  batch: 52 / 98  loss: 0.05506836582655804  hr: 0  min: 10  sec: 58\n",
            "epoch: 5  batch: 53 / 98  loss: 0.05839180400735646  hr: 0  min: 10  sec: 47\n",
            "epoch: 5  batch: 54 / 98  loss: 0.05950539810065594  hr: 0  min: 10  sec: 32\n",
            "epoch: 5  batch: 55 / 98  loss: 0.05885438545691696  hr: 0  min: 10  sec: 16\n",
            "epoch: 5  batch: 56 / 98  loss: 0.05796554675492059  hr: 0  min: 10  sec: 0\n",
            "epoch: 5  batch: 57 / 98  loss: 0.05711438236431333  hr: 0  min: 9  sec: 45\n",
            "epoch: 5  batch: 58 / 98  loss: 0.05712742246847985  hr: 0  min: 9  sec: 32\n",
            "epoch: 5  batch: 59 / 98  loss: 0.056762409893701134  hr: 0  min: 9  sec: 18\n",
            "epoch: 5  batch: 60 / 98  loss: 0.0572944171493873  hr: 0  min: 9  sec: 5\n",
            "epoch: 5  batch: 61 / 98  loss: 0.05676987050406513  hr: 0  min: 8  sec: 51\n",
            "epoch: 5  batch: 62 / 98  loss: 0.06149475148037797  hr: 0  min: 8  sec: 35\n",
            "epoch: 5  batch: 63 / 98  loss: 0.06167386014694496  hr: 0  min: 8  sec: 22\n",
            "epoch: 5  batch: 64 / 98  loss: 0.060928086248168256  hr: 0  min: 8  sec: 6\n",
            "epoch: 5  batch: 65 / 98  loss: 0.06020142206062491  hr: 0  min: 7  sec: 51\n",
            "epoch: 5  batch: 66 / 98  loss: 0.06273185438476503  hr: 0  min: 7  sec: 35\n",
            "epoch: 5  batch: 67 / 98  loss: 0.06217802209612816  hr: 0  min: 7  sec: 20\n",
            "epoch: 5  batch: 68 / 98  loss: 0.06279464202303  hr: 0  min: 7  sec: 5\n",
            "epoch: 5  batch: 69 / 98  loss: 0.06353355797709546  hr: 0  min: 6  sec: 51\n",
            "epoch: 5  batch: 70 / 98  loss: 0.06536666414966541  hr: 0  min: 6  sec: 36\n",
            "epoch: 5  batch: 71 / 98  loss: 0.06481532122231495  hr: 0  min: 6  sec: 21\n",
            "epoch: 5  batch: 72 / 98  loss: 0.06424686832017162  hr: 0  min: 6  sec: 5\n",
            "epoch: 5  batch: 73 / 98  loss: 0.06348685775436971  hr: 0  min: 5  sec: 50\n",
            "epoch: 5  batch: 74 / 98  loss: 0.0628245559307067  hr: 0  min: 5  sec: 37\n",
            "epoch: 5  batch: 75 / 98  loss: 0.06209820037707686  hr: 0  min: 5  sec: 23\n",
            "epoch: 5  batch: 76 / 98  loss: 0.06258368870169904  hr: 0  min: 5  sec: 9\n",
            "epoch: 5  batch: 77 / 98  loss: 0.061910162734278996  hr: 0  min: 4  sec: 55\n",
            "epoch: 5  batch: 78 / 98  loss: 0.06300590267906395  hr: 0  min: 4  sec: 41\n",
            "epoch: 5  batch: 79 / 98  loss: 0.06258421517979307  hr: 0  min: 4  sec: 26\n",
            "epoch: 5  batch: 80 / 98  loss: 0.06233415193273686  hr: 0  min: 4  sec: 13\n",
            "epoch: 5  batch: 81 / 98  loss: 0.06175876946337981  hr: 0  min: 3  sec: 59\n",
            "epoch: 5  batch: 82 / 98  loss: 0.06287599985896633  hr: 0  min: 3  sec: 45\n",
            "epoch: 5  batch: 83 / 98  loss: 0.062311152888304855  hr: 0  min: 3  sec: 31\n",
            "epoch: 5  batch: 84 / 98  loss: 0.06167073256801814  hr: 0  min: 3  sec: 17\n",
            "epoch: 5  batch: 85 / 98  loss: 0.06102231654941159  hr: 0  min: 3  sec: 3\n",
            "epoch: 5  batch: 86 / 98  loss: 0.06082764382170903  hr: 0  min: 2  sec: 49\n",
            "epoch: 5  batch: 87 / 98  loss: 0.0620777828929325  hr: 0  min: 2  sec: 35\n",
            "epoch: 5  batch: 88 / 98  loss: 0.06144792208215222  hr: 0  min: 2  sec: 21\n",
            "epoch: 5  batch: 89 / 98  loss: 0.06301051891523968  hr: 0  min: 2  sec: 7\n",
            "epoch: 5  batch: 90 / 98  loss: 0.06316101114886502  hr: 0  min: 1  sec: 53\n",
            "epoch: 5  batch: 91 / 98  loss: 0.06342092699340575  hr: 0  min: 1  sec: 39\n",
            "epoch: 5  batch: 92 / 98  loss: 0.06468726470357859  hr: 0  min: 1  sec: 24\n",
            "epoch: 5  batch: 93 / 98  loss: 0.06511683652417795  hr: 0  min: 1  sec: 10\n",
            "epoch: 5  batch: 94 / 98  loss: 0.0645361911812599  hr: 0  min: 0  sec: 56\n",
            "epoch: 5  batch: 95 / 98  loss: 0.06403796417442592  hr: 0  min: 0  sec: 42\n",
            "epoch: 5  batch: 96 / 98  loss: 0.06360049943032209  hr: 0  min: 0  sec: 28\n",
            "epoch: 5  batch: 97 / 98  loss: 0.06316697990675409  hr: 0  min: 0  sec: 14\n",
            "epoch: 5  batch: 98 / 98  loss: 0.06466781265786564  hr: 0  min: 0  sec: 0\n",
            "CPU times: user 1h 57min 26s, sys: 23min 4s, total: 2h 20min 31s\n",
            "Wall time: 2h 21min 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ],
      "metadata": {
        "id": "1neU4x1L1X0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ABSA = load_model(model_ABSA, 'drive/MyDrive/NLP/bert_ABSA2.pkl')"
      ],
      "metadata": {
        "id": "u3YMrmDovie8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "dywQcNeX1Tqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test on train dataset\n",
        "%time x, y = test_model_ABSA(train_loader)\n",
        "print(classification_report(x, y, target_names=[str(i) for i in range(3)], zero_division = 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LNHcWhsJ7fS",
        "outputId": "b3555f46-f09d-4cc1-8d3d-ce810f130641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6min 3s, sys: 26.6 s, total: 6min 30s\n",
            "Wall time: 6min 31s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       731\n",
            "           1       0.98      0.98      0.98       384\n",
            "           2       1.00      0.98      0.99       842\n",
            "\n",
            "    accuracy                           0.99      1957\n",
            "   macro avg       0.99      0.99      0.99      1957\n",
            "weighted avg       0.99      0.99      0.99      1957\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test on test dataset\n",
        "%time x, y = test_model_ABSA(test_loader)\n",
        "print(classification_report(x, y, target_names=[str(i) for i in range(3)], zero_division = 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjMglXu2vnSP",
        "outputId": "ba0f7612-c0de-4795-baac-82ddb06f5c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 20s, sys: 3.48 s, total: 1min 24s\n",
            "Wall time: 1min 29s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.89      0.79       150\n",
            "           1       0.62      0.54      0.58        71\n",
            "           2       0.90      0.72      0.80       136\n",
            "\n",
            "    accuracy                           0.75       357\n",
            "   macro avg       0.74      0.71      0.72       357\n",
            "weighted avg       0.77      0.75      0.75       357\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ABSA Test"
      ],
      "metadata": {
        "id": "mXyVTyQzdyVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"For the price you pay this product is very good. However, battery life is a little lack-luster coming from a MacBook Pro.\"\n",
        "aspect = [\"price\", \"battery life\"]\n",
        "print(predict_model_ABSA(text, \"battery life\", tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ejjy5yziW0_",
        "outputId": "a681f207-c260-4361-a1a5-e9f8298e5f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['[cls]', 'for', 'the', 'price', 'you', 'pay', 'this', 'product', 'is', 'very', 'good', '.', 'however', ',', 'battery', 'life', 'is', 'a', 'little', 'lack', '-', 'lust', '##er', 'coming', 'from', 'a', 'mac', '##book', 'pro', '.', '[sep]', 'battery', 'life'], tensor([0]), tensor([[ 2.5918, -2.4663, -0.4769]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The graphics are stunning\"\n",
        "print(predict_model_ABSA(text, \"graphics\", tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCc7Sy6gWbQH",
        "outputId": "94a0fe3e-bd18-452d-bac1-6850eb869e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['[cls]', 'the', 'graphics', 'are', 'stunning', '[sep]', 'graphics'], tensor([2]), tensor([[-2.1483, -2.4717,  4.4044]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main ABSA"
      ],
      "metadata": {
        "id": "JxDQMLSyEU53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ABSA = load_model(model_ABSA, 'drive/MyDrive/NLP/bert_ABSA2.pkl')\n",
        "model_ATE = load_model(model_ATE, 'drive/MyDrive/NLP/bert_ATE.pkl')"
      ],
      "metadata": {
        "id": "x9b5B0pHEalf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_pol(pol):\n",
        "  if pol == 0 :\n",
        "    return \"Negative\"\n",
        "  elif pol == 1:\n",
        "    return \"Neutral\"\n",
        "  elif pol == 2:\n",
        "    return \"Positive\"\n",
        "  else:\n",
        "    return \"None\""
      ],
      "metadata": {
        "id": "Qkmyzj-yFfBw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_model_ABSA(sentence, aspect, tokenizer):\n",
        "    t1 = tokenizer.tokenize(sentence)\n",
        "    t2 = tokenizer.tokenize(aspect)\n",
        "\n",
        "    word_pieces = ['[cls]']\n",
        "    word_pieces += t1\n",
        "    word_pieces += ['[sep]']\n",
        "    word_pieces += t2\n",
        "\n",
        "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
        "\n",
        "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
        "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
        "        _, predictions = torch.max(outputs, dim=1)\n",
        "    \n",
        "    return word_pieces, predictions, outputs\n",
        "\n",
        "def predict_model_ATE(sentence, tokenizer):\n",
        "    word_pieces = []\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    word_pieces += tokens\n",
        "\n",
        "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
        "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model_ATE(input_tensor, None, None)\n",
        "        _, predictions = torch.max(outputs, dim=2)\n",
        "    predictions = predictions[0].tolist()\n",
        "\n",
        "    return word_pieces, predictions, outputs\n",
        "\n",
        "def Main_ABSA(text):\n",
        "    terms = []\n",
        "    word = \"\"\n",
        "    x, y, z = predict_model_ATE(text, tokenizer)\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == 1:\n",
        "            if len(word) != 0:\n",
        "                terms.append(word.replace(\" ##\",\"\"))\n",
        "            word = x[i]\n",
        "        if y[i] == 2:\n",
        "            word += (\" \" + x[i])\n",
        "            \n",
        "    \n",
        "    if len(word) != 0:\n",
        "            terms.append(word.replace(\" ##\",\"\"))\n",
        "            \n",
        "    print(\"Aspect :\", terms)\n",
        "    \n",
        "    print(\"Sentiment :\")\n",
        "    if len(terms) != 0:\n",
        "        for i in terms:\n",
        "            _, c, p = predict_model_ABSA(text, i, tokenizer)\n",
        "            print(\"Aspect term:\", [i], \"Class:\", conv_pol(int(c)))\n"
      ],
      "metadata": {
        "id": "mNvpY_i8EWgF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"For the price you pay this product is very good. However, battery life is a little lack-luster coming from a MacBook Pro.\"\n",
        "Main_ABSA(text)"
      ],
      "metadata": {
        "id": "4agsfooZE0sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4730f4ca-a1dc-41f0-f0bd-72a5d8c44ec0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect : ['battery life']\n",
            "Sentiment :\n",
            "Aspect term: ['battery life'] Class: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"It absolutely is more expensive than most PC laptops, but the ease of use, security, and minimal problems that have arisen make it well worth the pricetag.\"\n",
        "Main_ABSA(text2)"
      ],
      "metadata": {
        "id": "dLS9MujFFaF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbda940d-ed42-4f4a-bc5b-b857d947bc42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect : ['use', 'security', ',', 'it']\n",
            "Sentiment :\n",
            "Aspect term: ['use'] Class: Positive\n",
            "Aspect term: ['security'] Class: Positive\n",
            "Aspect term: [','] Class: Negative\n",
            "Aspect term: ['it'] Class: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text3 = \"The graphics are stunning\"\n",
        "Main_ABSA(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0U_J1F8a-Mp",
        "outputId": "65e0f784-b36f-433a-c517-3fd2173344d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect : ['graphics']\n",
            "Sentiment :\n",
            "Aspect term: ['graphics'] Class: Positive\n"
          ]
        }
      ]
    }
  ]
}